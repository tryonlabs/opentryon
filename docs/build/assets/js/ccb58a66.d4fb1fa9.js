"use strict";(globalThis.webpackChunkopentryon_docs=globalThis.webpackChunkopentryon_docs||[]).push([[7295],{6388:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>t,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>a,toc:()=>d});const a=JSON.parse('{"id":"api-reference/nova-canvas","title":"Amazon Nova Canvas Virtual Try-On API","description":"The AmazonNovaCanvasVTONAdapter provides an interface to Amazon Nova Canvas Virtual Try-On model through AWS Bedrock for generating realistic virtual try-on images.","source":"@site/docs/api-reference/nova-canvas.md","sourceDirName":"api-reference","slug":"/api-reference/nova-canvas","permalink":"/opentryon/api-reference/nova-canvas","draft":false,"unlisted":false,"editUrl":"https://github.com/tryonlabs/opentryon/tree/main/docs/docs/api-reference/nova-canvas.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Kling AI Virtual Try-On API","permalink":"/opentryon/api-reference/kling-ai"},"next":{"title":"Segmind Virtual Try-On API","permalink":"/opentryon/api-reference/segmind"}}');var r=s(4848),i=s(8453);const l={},o="Amazon Nova Canvas Virtual Try-On API",t={},d=[{value:"Overview",id:"overview",level:2},{value:"Installation",id:"installation",level:2},{value:"Authentication",id:"authentication",level:2},{value:"Quick Start",id:"quick-start",level:2},{value:"API Reference",id:"api-reference",level:2},{value:"Class: <code>AmazonNovaCanvasVTONAdapter</code>",id:"class-amazonnovacanvasvtonadapter",level:3},{value:"Constructor",id:"constructor",level:4},{value:"Methods",id:"methods",level:4},{value:"<code>generate(source_image, reference_image, mask_type=&quot;GARMENT&quot;, garment_class=&quot;UPPER_BODY&quot;, mask_image=None)</code>",id:"generatesource_image-reference_image-mask_typegarment-garment_classupper_body-mask_imagenone",level:5},{value:"<code>generate_and_decode(source_image, reference_image, mask_type=&quot;GARMENT&quot;, garment_class=&quot;UPPER_BODY&quot;, mask_image=None)</code>",id:"generate_and_decodesource_image-reference_image-mask_typegarment-garment_classupper_body-mask_imagenone",level:5},{value:"<code>validate_image_size(image)</code>",id:"validate_image_sizeimage",level:5},{value:"Image Size Limits",id:"image-size-limits",level:2},{value:"Mask Types",id:"mask-types",level:2},{value:"GARMENT Mask (Default)",id:"garment-mask-default",level:3},{value:"IMAGE Mask",id:"image-mask",level:3},{value:"Supported AWS Regions",id:"supported-aws-regions",level:2},{value:"Image Input Formats",id:"image-input-formats",level:2},{value:"File Paths",id:"file-paths",level:3},{value:"File-like Objects",id:"file-like-objects",level:3},{value:"Complete Example",id:"complete-example",level:2},{value:"Error Handling",id:"error-handling",level:2},{value:"Best Practices",id:"best-practices",level:2},{value:"AWS Credentials",id:"aws-credentials",level:3},{value:"Enable Model Access",id:"enable-model-access",level:3},{value:"Image Preprocessing",id:"image-preprocessing",level:3},{value:"Mask Type Selection",id:"mask-type-selection",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"AWS Credentials Issues",id:"aws-credentials-issues",level:3},{value:"Model Access Denied",id:"model-access-denied",level:3},{value:"Image Format Issues",id:"image-format-issues",level:3},{value:"Invalid Parameters",id:"invalid-parameters",level:3},{value:"See Also",id:"see-also",level:2}];function c(e){const n={a:"a",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",h5:"h5",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"amazon-nova-canvas-virtual-try-on-api",children:"Amazon Nova Canvas Virtual Try-On API"})}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"AmazonNovaCanvasVTONAdapter"})," provides an interface to Amazon Nova Canvas Virtual Try-On model through AWS Bedrock for generating realistic virtual try-on images."]}),"\n",(0,r.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,r.jsx)(n.p,{children:"Amazon Nova Canvas Virtual Try-On combines a source image (person/model) with a reference image (garment/product) to create realistic virtual try-on results. The adapter handles AWS authentication, image preparation, and response decoding automatically."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Service:"})," Amazon Bedrock Runtime API",(0,r.jsx)(n.br,{}),"\n",(0,r.jsx)(n.strong,{children:"Model ID:"})," ",(0,r.jsx)(n.code,{children:"amazon.nova-canvas-v1:0"}),(0,r.jsx)(n.br,{}),"\n",(0,r.jsx)(n.strong,{children:"Reference:"})," ",(0,r.jsx)(n.a,{href:"https://aws.amazon.com/blogs/aws/amazon-nova-canvas-update-virtual-try-on-and-style-options-now-available/",children:"Amazon Nova Canvas Documentation"})]}),"\n",(0,r.jsx)(n.h2,{id:"installation",children:"Installation"}),"\n",(0,r.jsxs)(n.p,{children:["The adapter requires ",(0,r.jsx)(n.code,{children:"boto3"})," and ",(0,r.jsx)(n.code,{children:"botocore"})," libraries:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"pip install boto3 botocore pillow\n"})}),"\n",(0,r.jsx)(n.h2,{id:"authentication",children:"Authentication"}),"\n",(0,r.jsx)(n.p,{children:"Amazon Nova Canvas uses AWS credentials for authentication. Configure credentials using one of these methods:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"AWS Credentials File"})," (",(0,r.jsx)(n.code,{children:"~/.aws/credentials"}),"):"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-ini",children:"[default]\naws_access_key_id = YOUR_ACCESS_KEY\naws_secret_access_key = YOUR_SECRET_KEY\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Environment Variables"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'export AWS_ACCESS_KEY_ID="your_access_key"\nexport AWS_SECRET_ACCESS_KEY="your_secret_key"\nexport AWS_DEFAULT_REGION="us-east-1"\n'})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"IAM Role"})," (if running on EC2/ECS/Lambda)"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Important:"})," Ensure Nova Canvas model access is enabled in your AWS Bedrock console (Model access section)."]}),"\n",(0,r.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from tryon.api import AmazonNovaCanvasVTONAdapter\n\n# Initialize adapter\nadapter = AmazonNovaCanvasVTONAdapter(region="us-east-1")\n\n# Generate virtual try-on images\nimages = adapter.generate_and_decode(\n    source_image="data/person.jpg",\n    reference_image="data/garment.jpg",\n    mask_type="GARMENT",\n    garment_class="UPPER_BODY"\n)\n\n# Save results\nfor idx, image in enumerate(images):\n    image.save(f"outputs/result_{idx}.png")\n'})}),"\n",(0,r.jsx)(n.h2,{id:"api-reference",children:"API Reference"}),"\n",(0,r.jsxs)(n.h3,{id:"class-amazonnovacanvasvtonadapter",children:["Class: ",(0,r.jsx)(n.code,{children:"AmazonNovaCanvasVTONAdapter"})]}),"\n",(0,r.jsx)(n.p,{children:"Adapter class for Amazon Nova Canvas Virtual Try-On API."}),"\n",(0,r.jsx)(n.h4,{id:"constructor",children:"Constructor"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"AmazonNovaCanvasVTONAdapter(region: Optional[str] = None)\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"region"})," (str, optional): AWS region name. Defaults to ",(0,r.jsx)(n.code,{children:"AMAZON_NOVA_REGION"})," environment variable or ",(0,r.jsx)(n.code,{children:"'us-east-1'"})," if not set. Supported regions:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"'us-east-1'"})," (US East - N. Virginia) - Default"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"'ap-northeast-1'"})," (Asia Pacific - Tokyo)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"'eu-west-1'"})," (Europe - Ireland)"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Example:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Use default region (us-east-1)\nadapter = AmazonNovaCanvasVTONAdapter()\n\n# Use custom region\nadapter = AmazonNovaCanvasVTONAdapter(region="ap-northeast-1")\n'})}),"\n",(0,r.jsx)(n.h4,{id:"methods",children:"Methods"}),"\n",(0,r.jsx)(n.h5,{id:"generatesource_image-reference_image-mask_typegarment-garment_classupper_body-mask_imagenone",children:(0,r.jsx)(n.code,{children:'generate(source_image, reference_image, mask_type="GARMENT", garment_class="UPPER_BODY", mask_image=None)'})}),"\n",(0,r.jsx)(n.p,{children:"Generate virtual try-on image(s) using Amazon Nova Canvas."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"source_image"})," (str or io.BytesIO): Source image (person/model) - file path or file-like object. Must be max 4.1M pixels (2048x2048)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"reference_image"})," (str or io.BytesIO): Reference image (garment/product) - file path or file-like object. Must be max 4.1M pixels (2048x2048)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"mask_type"})," (str): Type of mask to use:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:'"GARMENT"'}),": Automatically detects garment area (default)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:'"IMAGE"'}),": Uses custom black-and-white mask image"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"garment_class"})," (str, optional): Garment class for GARMENT mask type. Options:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:'"UPPER_BODY"'}),": Tops, shirts, jackets, hoodies (default)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:'"LOWER_BODY"'}),": Pants, skirts, shorts"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:'"FULL_BODY"'}),": Dresses, jumpsuits"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:'"FOOTWEAR"'}),": Shoes, boots\nRequired when ",(0,r.jsx)(n.code,{children:"mask_type"})," is ",(0,r.jsx)(n.code,{children:'"GARMENT"'})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"mask_image"})," (str or io.BytesIO, optional): Mask image for IMAGE mask type. Black areas will be replaced, white areas will be preserved. Required when ",(0,r.jsx)(n.code,{children:"mask_type"})," is ",(0,r.jsx)(n.code,{children:'"IMAGE"'})]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Returns:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"List[str]"}),": List of generated images as Base64 encoded strings"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Raises:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"ValueError"}),": If images exceed size limits, required parameters are missing, or API returns an error"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Example:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Using GARMENT mask type (default)\nimages_base64 = adapter.generate(\n    source_image="person.jpg",\n    reference_image="shirt.jpg",\n    mask_type="GARMENT",\n    garment_class="UPPER_BODY"\n)\n\n# Using IMAGE mask type\nimages_base64 = adapter.generate(\n    source_image="person.jpg",\n    reference_image="garment.jpg",\n    mask_type="IMAGE",\n    mask_image="mask.png"\n)\n'})}),"\n",(0,r.jsx)(n.h5,{id:"generate_and_decodesource_image-reference_image-mask_typegarment-garment_classupper_body-mask_imagenone",children:(0,r.jsx)(n.code,{children:'generate_and_decode(source_image, reference_image, mask_type="GARMENT", garment_class="UPPER_BODY", mask_image=None)'})}),"\n",(0,r.jsx)(n.p,{children:"Generate virtual try-on images and decode them to PIL Image objects."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Same as ",(0,r.jsx)(n.code,{children:"generate()"})," method"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Returns:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"List[PIL.Image.Image]"}),": List of PIL Image objects ready for display or saving"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Raises:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"ValueError"}),": If images exceed size limits, required parameters are missing, or image decoding fails"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Example:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'images = adapter.generate_and_decode(\n    source_image="data/person.jpg",\n    reference_image="data/garment.jpg",\n    mask_type="GARMENT",\n    garment_class="UPPER_BODY"\n)\n\n# Save all results\nfor idx, image in enumerate(images):\n    image.save(f"outputs/vton_result_{idx}.png")\n'})}),"\n",(0,r.jsx)(n.h5,{id:"validate_image_sizeimage",children:(0,r.jsx)(n.code,{children:"validate_image_size(image)"})}),"\n",(0,r.jsx)(n.p,{children:"Validate that image dimensions meet Nova Canvas requirements."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"image"})," (PIL.Image.Image): PIL Image object to validate"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Raises:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"ValueError"}),": If image exceeds size limits"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Note:"})," This method is called automatically when loading images. You typically don't need to call it directly."]}),"\n",(0,r.jsx)(n.h2,{id:"image-size-limits",children:"Image Size Limits"}),"\n",(0,r.jsx)(n.p,{children:"Amazon Nova Canvas has the following image size requirements:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Maximum image pixels:"})," 4,100,000 pixels (equivalent to 2,048 x 2,048)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Maximum dimension:"})," 2,048 pixels per side"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Supported formats:"})," JPG, PNG"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Images are automatically validated before sending to the API. If an image exceeds these limits, a ",(0,r.jsx)(n.code,{children:"ValueError"})," is raised with a helpful message."]}),"\n",(0,r.jsx)(n.h2,{id:"mask-types",children:"Mask Types"}),"\n",(0,r.jsx)(n.p,{children:"Nova Canvas supports two mask types:"}),"\n",(0,r.jsx)(n.h3,{id:"garment-mask-default",children:"GARMENT Mask (Default)"}),"\n",(0,r.jsx)(n.p,{children:"Automatically detects and masks the garment area based on garment class. This is the recommended approach for most use cases."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Garment Classes:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"UPPER_BODY"})}),": Tops, shirts, jackets, hoodies"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"LOWER_BODY"})}),": Pants, skirts, shorts"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"FULL_BODY"})}),": Dresses, jumpsuits"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"FOOTWEAR"})}),": Shoes, boots"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Example:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Upper body garment\nimages = adapter.generate_and_decode(\n    source_image="person.jpg",\n    reference_image="shirt.jpg",\n    mask_type="GARMENT",\n    garment_class="UPPER_BODY"\n)\n\n# Lower body garment\nimages = adapter.generate_and_decode(\n    source_image="person.jpg",\n    reference_image="pants.jpg",\n    mask_type="GARMENT",\n    garment_class="LOWER_BODY"\n)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"image-mask",children:"IMAGE Mask"}),"\n",(0,r.jsx)(n.p,{children:"Uses a custom black-and-white mask image where:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Black areas"})," = replaced with garment"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"White areas"})," = preserved from source image"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Example:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'images = adapter.generate_and_decode(\n    source_image="person.jpg",\n    reference_image="garment.jpg",\n    mask_type="IMAGE",\n    mask_image="custom_mask.png"\n)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"supported-aws-regions",children:"Supported AWS Regions"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"us-east-1"})})," (US East - N. Virginia) - Default"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"ap-northeast-1"})})," (Asia Pacific - Tokyo)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"eu-west-1"})})," (Europe - Ireland)"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"image-input-formats",children:"Image Input Formats"}),"\n",(0,r.jsx)(n.p,{children:"The adapter supports multiple input formats:"}),"\n",(0,r.jsx)(n.h3,{id:"file-paths",children:"File Paths"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'images = adapter.generate_and_decode(\n    source_image="data/person.jpg",\n    reference_image="data/garment.jpg"\n)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"file-like-objects",children:"File-like Objects"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from io import BytesIO\n\nwith open("person.jpg", "rb") as f:\n    person_bytes = BytesIO(f.read())\n\nwith open("garment.jpg", "rb") as f:\n    garment_bytes = BytesIO(f.read())\n\nimages = adapter.generate_and_decode(\n    source_image=person_bytes,\n    reference_image=garment_bytes\n)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"complete-example",children:"Complete Example"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from tryon.api import AmazonNovaCanvasVTONAdapter\nfrom PIL import Image\n\n# Initialize adapter\nadapter = AmazonNovaCanvasVTONAdapter(region="us-east-1")\n\n# Generate try-on for upper body garment\nimages = adapter.generate_and_decode(\n    source_image="data/person.jpg",\n    reference_image="data/shirt.jpg",\n    mask_type="GARMENT",\n    garment_class="UPPER_BODY"\n)\n\n# Generate try-on for lower body garment\nimages = adapter.generate_and_decode(\n    source_image="data/person.jpg",\n    reference_image="data/pants.jpg",\n    mask_type="GARMENT",\n    garment_class="LOWER_BODY"\n)\n\n# Process results\nfor idx, image in enumerate(images):\n    # Save image\n    image.save(f"outputs/result_{idx}.png")\n    \n    # Display image (if in Jupyter)\n    # display(image)\n    \n    # Get image info\n    print(f"Image {idx}: {image.size} ({image.mode})")\n'})}),"\n",(0,r.jsx)(n.h2,{id:"error-handling",children:"Error Handling"}),"\n",(0,r.jsxs)(n.p,{children:["The adapter raises ",(0,r.jsx)(n.code,{children:"ValueError"})," for common errors:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'try:\n    images = adapter.generate_and_decode(\n        source_image="person.jpg",\n        reference_image="garment.jpg"\n    )\nexcept ValueError as e:\n    print(f"Error: {e}")\n    # Handle error...\n'})}),"\n",(0,r.jsx)(n.p,{children:"Common errors:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Missing AWS credentials"}),"\n",(0,r.jsx)(n.li,{children:"Nova Canvas not enabled in AWS account"}),"\n",(0,r.jsx)(n.li,{children:"Invalid image format or size"}),"\n",(0,r.jsx)(n.li,{children:"Invalid mask type or garment class"}),"\n",(0,r.jsx)(n.li,{children:"API request failure"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,r.jsx)(n.h3,{id:"aws-credentials",children:"AWS Credentials"}),"\n",(0,r.jsx)(n.p,{children:"Store your AWS credentials securely:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Using AWS CLI\naws configure\n\n# Or using environment variables\nexport AWS_ACCESS_KEY_ID="your_access_key"\nexport AWS_SECRET_ACCESS_KEY="your_secret_key"\nexport AWS_DEFAULT_REGION="us-east-1"\n'})}),"\n",(0,r.jsx)(n.h3,{id:"enable-model-access",children:"Enable Model Access"}),"\n",(0,r.jsx)(n.p,{children:"Before using Nova Canvas, ensure model access is enabled:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Go to AWS Bedrock Console"}),"\n",(0,r.jsx)(n.li,{children:'Navigate to "Model access" section'}),"\n",(0,r.jsx)(n.li,{children:'Enable "Amazon Nova Canvas" for your desired region(s)'}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"image-preprocessing",children:"Image Preprocessing"}),"\n",(0,r.jsx)(n.p,{children:"For best results:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Use high-resolution images (at least 512x512)"}),"\n",(0,r.jsx)(n.li,{children:"Ensure person image shows full body or relevant body part"}),"\n",(0,r.jsx)(n.li,{children:"Use clear, well-lit images"}),"\n",(0,r.jsx)(n.li,{children:"Remove background if possible"}),"\n",(0,r.jsx)(n.li,{children:"Ensure images meet size requirements (max 4.1M pixels, 2048x2048)"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"mask-type-selection",children:"Mask Type Selection"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Use GARMENT mask"})," for standard garment types (upper body, lower body, etc.)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Use IMAGE mask"})," only when you need precise control over the replacement area"]}),"\n",(0,r.jsx)(n.li,{children:"Ensure mask images are black-and-white (grayscale) for IMAGE mask type"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,r.jsx)(n.h3,{id:"aws-credentials-issues",children:"AWS Credentials Issues"}),"\n",(0,r.jsx)(n.p,{children:"If you get authentication errors:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Verify AWS credentials are configured correctly"}),"\n",(0,r.jsxs)(n.li,{children:["Check credentials file: ",(0,r.jsx)(n.code,{children:"cat ~/.aws/credentials"})]}),"\n",(0,r.jsxs)(n.li,{children:["Verify environment variables: ",(0,r.jsx)(n.code,{children:"echo $AWS_ACCESS_KEY_ID"})]}),"\n",(0,r.jsxs)(n.li,{children:["Test AWS CLI: ",(0,r.jsx)(n.code,{children:"aws sts get-caller-identity"})]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"model-access-denied",children:"Model Access Denied"}),"\n",(0,r.jsx)(n.p,{children:'If you get "AccessDeniedException":'}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Go to AWS Bedrock Console > Model access"}),"\n",(0,r.jsx)(n.li,{children:'Enable "Amazon Nova Canvas" for your region'}),"\n",(0,r.jsx)(n.li,{children:"Wait a few minutes for changes to propagate"}),"\n",(0,r.jsx)(n.li,{children:"Verify region supports Nova Canvas (us-east-1, ap-northeast-1, eu-west-1)"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"image-format-issues",children:"Image Format Issues"}),"\n",(0,r.jsx)(n.p,{children:"If images fail to process:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Verify image files exist and are readable"}),"\n",(0,r.jsx)(n.li,{children:"Check image format is supported (JPG, PNG)"}),"\n",(0,r.jsx)(n.li,{children:"Ensure images meet size requirements (max 4.1M pixels, 2048x2048)"}),"\n",(0,r.jsx)(n.li,{children:"Try converting images to RGB format"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"invalid-parameters",children:"Invalid Parameters"}),"\n",(0,r.jsx)(n.p,{children:"If you get validation errors:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Verify ",(0,r.jsx)(n.code,{children:"mask_type"})," is either ",(0,r.jsx)(n.code,{children:'"GARMENT"'})," or ",(0,r.jsx)(n.code,{children:'"IMAGE"'})]}),"\n",(0,r.jsxs)(n.li,{children:["Ensure ",(0,r.jsx)(n.code,{children:"garment_class"})," is provided when using ",(0,r.jsx)(n.code,{children:'"GARMENT"'})," mask type"]}),"\n",(0,r.jsxs)(n.li,{children:["Ensure ",(0,r.jsx)(n.code,{children:"mask_image"})," is provided when using ",(0,r.jsx)(n.code,{children:'"IMAGE"'})," mask type"]}),"\n",(0,r.jsxs)(n.li,{children:["Check garment class is one of: ",(0,r.jsx)(n.code,{children:"UPPER_BODY"}),", ",(0,r.jsx)(n.code,{children:"LOWER_BODY"}),", ",(0,r.jsx)(n.code,{children:"FULL_BODY"}),", ",(0,r.jsx)(n.code,{children:"FOOTWEAR"})]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"see-also",children:"See Also"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"../examples/virtual-tryon",children:"Virtual Try-On Examples"})," - Usage examples"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"overview",children:"API Reference Overview"})," - Complete API reference"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://aws.amazon.com/blogs/aws/amazon-nova-canvas-update-virtual-try-on-and-style-options-now-available/",children:"Amazon Nova Canvas Documentation"})," - Official AWS documentation"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>l,x:()=>o});var a=s(6540);const r={},i=a.createContext(r);function l(e){const n=a.useContext(i);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),a.createElement(i.Provider,{value:n},e.children)}}}]);