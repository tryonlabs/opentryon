"use strict";(globalThis.webpackChunkopentryon_docs=globalThis.webpackChunkopentryon_docs||[]).push([[4211],{160:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>t,contentTitle:()=>o,default:()=>p,frontMatter:()=>r,metadata:()=>l,toc:()=>d});const l=JSON.parse('{"id":"agents/model-swap-agent","title":"Model Swap Agent","description":"LangChain-based agent that intelligently replaces models/people in images while preserving outfits and styling using multiple AI models.","source":"@site/docs/agents/model-swap-agent.md","sourceDirName":"agents","slug":"/agents/model-swap-agent","permalink":"/opentryon/agents/model-swap-agent","draft":false,"unlisted":false,"editUrl":"https://github.com/tryonlabs/opentryon/tree/main/docs/docs/agents/model-swap-agent.md","tags":[],"version":"current","frontMatter":{"title":"Model Swap Agent","description":"LangChain-based agent that intelligently replaces models/people in images while preserving outfits and styling using multiple AI models.","keywords":["model swap agent","langchain agent","nano banana","flux2","AI agent","model replacement","outfit preservation"]},"sidebar":"tutorialSidebar","previous":{"title":"Virtual Try-On Agent","permalink":"/opentryon/agents/vton-agent"},"next":{"title":"Contributing","permalink":"/opentryon/community/contributing"}}');var s=i(4848),a=i(8453);const r={title:"Model Swap Agent",description:"LangChain-based agent that intelligently replaces models/people in images while preserving outfits and styling using multiple AI models.",keywords:["model swap agent","langchain agent","nano banana","flux2","AI agent","model replacement","outfit preservation"]},o="Model Swap Agent",t={},d=[{value:"Overview",id:"overview",level:2},{value:"Supported Models",id:"supported-models",level:3},{value:"Features",id:"features",level:2},{value:"Installation",id:"installation",level:2},{value:"Quick Start",id:"quick-start",level:2},{value:"Usage",id:"usage",level:2},{value:"Command Line Interface",id:"command-line-interface",level:3},{value:"CLI Arguments",id:"cli-arguments",level:4},{value:"Python API Usage",id:"python-api-usage",level:3},{value:"Basic Usage",id:"basic-usage",level:4},{value:"Using Different Models",id:"using-different-models",level:4},{value:"Using Different LLM Providers",id:"using-different-llm-providers",level:4},{value:"Attribute Extraction",id:"attribute-extraction",level:3},{value:"Example Prompts",id:"example-prompts",level:3},{value:"Model Comparison",id:"model-comparison",level:2},{value:"Resolution Options (Nano Banana Pro)",id:"resolution-options-nano-banana-pro",level:2},{value:"Environment Variables",id:"environment-variables",level:2},{value:"API Reference",id:"api-reference",level:2},{value:"ModelSwapAgent",id:"modelswapagent",level:3},{value:"<code>__init__(llm_provider, llm_model=None, temperature=0.0, api_key=None, model=None, **llm_kwargs)</code>",id:"__init__llm_provider-llm_modelnone-temperature00-api_keynone-modelnone-llm_kwargs",level:4},{value:"<code>generate(image, prompt, resolution=None, use_search_grounding=False, verbose=False, **kwargs)</code>",id:"generateimage-prompt-resolutionnone-use_search_groundingfalse-verbosefalse-kwargs",level:4},{value:"Examples",id:"examples",level:2},{value:"Example 1: Basic Model Swap",id:"example-1-basic-model-swap",level:3},{value:"Example 2: High-Quality with FLUX 2 Pro",id:"example-2-high-quality-with-flux-2-pro",level:3},{value:"Example 3: 4K Professional Quality",id:"example-3-4k-professional-quality",level:3},{value:"Example 4: Advanced Control with FLUX 2 Flex",id:"example-4-advanced-control-with-flux-2-flex",level:3},{value:"How It Works",id:"how-it-works",level:2},{value:"Best Practices",id:"best-practices",level:2},{value:"Use Cases",id:"use-cases",level:2},{value:"Limitations",id:"limitations",level:2},{value:"Future Enhancements",id:"future-enhancements",level:2},{value:"Related Documentation",id:"related-documentation",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"model-swap-agent",children:"Model Swap Agent"})}),"\n",(0,s.jsx)(n.p,{children:"A LangChain-based AI agent that intelligently replaces models/people in images while perfectly preserving outfits and styling. Perfect for e-commerce sellers and fashion brands to create professional product imagery with diverse models."}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"The Model Swap Agent uses LangChain to analyze natural language prompts and extract detailed person attributes, then generates professional model-swapped images while maintaining the exact outfit, clothing details, patterns, and styling."}),"\n",(0,s.jsx)(n.h3,{id:"supported-models",children:"Supported Models"}),"\n",(0,s.jsx)(n.p,{children:"The agent supports multiple AI models for model swapping:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Nano Banana"})," (Gemini 2.5 Flash Image): Fast generation at 1024px resolution, ideal for quick iterations"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Nano Banana Pro"})," (Gemini 3 Pro Image Preview): High-quality 4K resolution with search grounding support (default)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"FLUX 2 Pro"}),": Professional quality with custom width/height control"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"FLUX 2 Flex"}),": Advanced controls (guidance scale, steps) for fine-tuned generation"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"features",children:"Features"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Intelligent Attribute Extraction"}),": Automatically extracts gender, age, ethnicity, body type, pose, and styling from natural language prompts"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Perfect Outfit Preservation"}),": Maintains exact clothing details, colors, patterns, textures, and fit"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Multi-Model Support"}),": Choose from 4 different AI models based on your needs"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"High-Resolution Output"}),": Up to 4K resolution for professional e-commerce quality"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Natural Language Interface"}),': Simple prompts like "Replace with a professional Asian female model in her 30s"']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Multiple LLM Support"}),": Works with OpenAI, Anthropic Claude, and Google Gemini"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Professional Quality"}),": Maintains lighting, background, composition, and photography standards"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"installation",children:"Installation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"pip install langchain langchain-openai langchain-anthropic langchain-google-genai\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Note"}),": This agent uses LangChain 1.x API (",(0,s.jsx)(n.code,{children:"create_agent"}),"). See ",(0,s.jsx)(n.a,{href:"https://docs.langchain.com/oss/python/langchain/agents",children:"LangChain 1.x documentation"})," for details."]}),"\n",(0,s.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from tryon.agents.model_swap import ModelSwapAgent\n\n# Initialize agent with default Nano Banana Pro\nagent = ModelSwapAgent(llm_provider="openai")\n\n# Generate model swap\nresult = agent.generate(\n    image="person_wearing_outfit.jpg",\n    prompt="Replace with a professional Asian female model in her 30s, athletic build"\n)\n\nif result["status"] == "success":\n    for idx, image in enumerate(result[\'images\']):\n        image.save(f"swapped_model_{idx}.png")\n'})}),"\n",(0,s.jsx)(n.h2,{id:"usage",children:"Usage"}),"\n",(0,s.jsx)(n.h3,{id:"command-line-interface",children:"Command Line Interface"}),"\n",(0,s.jsx)(n.p,{children:"The Model Swap Agent includes a command-line interface for easy usage:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# Basic usage with default Nano Banana Pro\npython model_swap_agent.py \\\n    --image model.jpg \\\n    --prompt "Replace with a professional male model in his 30s, athletic build"\n\n# Use FLUX 2 Pro for high-quality results\npython model_swap_agent.py \\\n    --image model.jpg \\\n    --prompt "Replace with a professional female model" \\\n    --model flux2_pro\n\n# Use FLUX 2 Flex for advanced control\npython model_swap_agent.py \\\n    --image model.jpg \\\n    --prompt "Replace with an athletic Asian model" \\\n    --model flux2_flex\n\n# Use Nano Banana for fast generation\npython model_swap_agent.py \\\n    --image model.jpg \\\n    --prompt "Replace with a professional model" \\\n    --model nano_banana\n\n# Specify resolution for Nano Banana Pro\npython model_swap_agent.py \\\n    --image model.jpg \\\n    --prompt "Male model in his 30s" \\\n    --model nano_banana_pro \\\n    --resolution 2K\n\n# Use Google Search grounding (Nano Banana Pro only)\npython model_swap_agent.py \\\n    --image model.jpg \\\n    --prompt "Model like professional fashion runway" \\\n    --model nano_banana_pro \\\n    --search-grounding\n\n# Use different LLM provider\npython model_swap_agent.py \\\n    --image model.jpg \\\n    --prompt "Plus-size woman, African American, 40s" \\\n    --llm-provider anthropic \\\n    --model flux2_pro\n\n# Use URLs instead of file paths\npython model_swap_agent.py \\\n    --image https://example.com/model.jpg \\\n    --prompt "Female model, 30s, professional" \\\n    --model flux2_pro\n\n# Verbose output to see agent reasoning\npython model_swap_agent.py \\\n    --image model.jpg \\\n    --prompt "Male model in 30s" \\\n    --verbose\n'})}),"\n",(0,s.jsx)(n.h4,{id:"cli-arguments",children:"CLI Arguments"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"--image"}),", ",(0,s.jsx)(n.code,{children:"-i"}),": Path or URL to image of person wearing outfit (required)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"--prompt"}),": Description of desired model/person (required)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"--model"}),": Model to use for swapping (default: ",(0,s.jsx)(n.code,{children:"nano_banana_pro"}),", options: ",(0,s.jsx)(n.code,{children:"nano_banana"}),", ",(0,s.jsx)(n.code,{children:"nano_banana_pro"}),", ",(0,s.jsx)(n.code,{children:"flux2_pro"}),", ",(0,s.jsx)(n.code,{children:"flux2_flex"}),")"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"--resolution"}),": Output resolution for Nano Banana Pro (default: ",(0,s.jsx)(n.code,{children:"4K"}),", options: ",(0,s.jsx)(n.code,{children:"1K"}),", ",(0,s.jsx)(n.code,{children:"2K"}),", ",(0,s.jsx)(n.code,{children:"4K"}),")"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"--search-grounding"}),": Use Google Search grounding for real-world references (Nano Banana Pro only)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"--llm-provider"}),": LLM provider to use (default: ",(0,s.jsx)(n.code,{children:"openai"}),", options: ",(0,s.jsx)(n.code,{children:"openai"}),", ",(0,s.jsx)(n.code,{children:"anthropic"}),", ",(0,s.jsx)(n.code,{children:"google"}),")"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"--llm-model"}),": Specific LLM model name (optional, uses default for provider)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"--llm-temperature"}),": Temperature for LLM (default: ",(0,s.jsx)(n.code,{children:"0.0"}),")"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"--llm-api-key"}),": API key for LLM provider (optional, can use environment variables)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"--output-dir"}),", ",(0,s.jsx)(n.code,{children:"-o"}),": Directory to save generated images (default: ",(0,s.jsx)(n.code,{children:"outputs/"}),")"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"--save-base64"}),": Also save Base64 encoded strings to .txt files"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"--verbose"}),": Print verbose output including agent reasoning steps"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"python-api-usage",children:"Python API Usage"}),"\n",(0,s.jsx)(n.h4,{id:"basic-usage",children:"Basic Usage"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from tryon.agents.model_swap import ModelSwapAgent\n\n# Initialize agent with default Nano Banana Pro\nagent = ModelSwapAgent(llm_provider="openai")\n\n# Generate model swap\nresult = agent.generate(\n    image="person_wearing_outfit.jpg",\n    prompt="Replace with a professional male model in his 30s, athletic build"\n)\n\nif result["status"] == "success":\n    images = result[\'images\']\n    for idx, image in enumerate(images):\n        image.save(f"result_{idx}.png")\n'})}),"\n",(0,s.jsx)(n.h4,{id:"using-different-models",children:"Using Different Models"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Nano Banana (fast, 1024px)\nagent = ModelSwapAgent(llm_provider="openai", model="nano_banana")\nresult = agent.generate(\n    image="model.jpg",\n    prompt="Replace with a professional model"\n)\n\n# Nano Banana Pro (4K, default)\nagent = ModelSwapAgent(llm_provider="openai", model="nano_banana_pro")\nresult = agent.generate(\n    image="model.jpg",\n    prompt="Replace with a professional model",\n    resolution="4K",\n    use_search_grounding=False\n)\n\n# FLUX 2 Pro (high quality)\nagent = ModelSwapAgent(llm_provider="openai", model="flux2_pro")\nresult = agent.generate(\n    image="model.jpg",\n    prompt="Replace with a professional model"\n)\n\n# FLUX 2 Flex (advanced controls)\nagent = ModelSwapAgent(llm_provider="openai", model="flux2_flex")\nresult = agent.generate(\n    image="model.jpg",\n    prompt="Replace with a professional model"\n)\n'})}),"\n",(0,s.jsx)(n.h4,{id:"using-different-llm-providers",children:"Using Different LLM Providers"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# OpenAI (default)\nagent = ModelSwapAgent(llm_provider="openai", llm_model="gpt-4")\n\n# Anthropic Claude\nagent = ModelSwapAgent(llm_provider="anthropic", llm_model="claude-3-opus-20240229")\n\n# Google Gemini\nagent = ModelSwapAgent(llm_provider="google", llm_model="gemini-2.5-pro")\n'})}),"\n",(0,s.jsx)(n.h3,{id:"attribute-extraction",children:"Attribute Extraction"}),"\n",(0,s.jsx)(n.p,{children:"The agent automatically extracts the following attributes from your prompts:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Gender"}),": Male, female, non-binary, or unspecified"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Age Range"}),": Teens, 20s, 30s, 40s, 50s+"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Ethnicity/Appearance"}),": Asian, African, Caucasian, Hispanic, Middle Eastern, mixed, diverse, or unspecified"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Body Type"}),": Slim, athletic, average, curvy, plus-size, muscular"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Facial Features"}),": Sharp features, soft features, distinctive characteristics"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Pose/Expression"}),": Confident, casual, professional, friendly, serious, natural"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Styling Preferences"}),": Professional, casual, editorial, commercial, lifestyle"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"example-prompts",children:"Example Prompts"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Basic Descriptions:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'"Professional male model in his 30s"\n"Female model, mid-20s, athletic build"\n"Plus-size woman, friendly expression"\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Detailed Descriptions:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'"Professional Asian female model in her early 30s, athletic build, \nconfident posture, sharp features, editorial style photography"\n\n"Athletic male model, African American, late 20s, muscular build,\ncasual confident pose, commercial photography style"\n\n"Plus-size woman, Caucasian, 40s, warm friendly expression,\nlifestyle photography, natural lighting"\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Style References:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'"Professional fashion runway model style"\n"Commercial lifestyle photography model"\n"Editorial high-fashion model aesthetic"\n'})}),"\n",(0,s.jsx)(n.h2,{id:"model-comparison",children:"Model Comparison"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Model"}),(0,s.jsx)(n.th,{children:"Resolution"}),(0,s.jsx)(n.th,{children:"Speed"}),(0,s.jsx)(n.th,{children:"Quality"}),(0,s.jsx)(n.th,{children:"Best For"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Nano Banana"})}),(0,s.jsx)(n.td,{children:"1024px"}),(0,s.jsx)(n.td,{children:"Fast \u26a1"}),(0,s.jsx)(n.td,{children:"Good"}),(0,s.jsx)(n.td,{children:"Quick iterations, testing"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Nano Banana Pro"})}),(0,s.jsx)(n.td,{children:"Up to 4K"}),(0,s.jsx)(n.td,{children:"Medium"}),(0,s.jsx)(n.td,{children:"Excellent"}),(0,s.jsx)(n.td,{children:"Professional e-commerce (default)"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"FLUX 2 Pro"})}),(0,s.jsx)(n.td,{children:"Custom"}),(0,s.jsx)(n.td,{children:"Medium"}),(0,s.jsx)(n.td,{children:"High"}),(0,s.jsx)(n.td,{children:"Professional quality with custom dimensions"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"FLUX 2 Flex"})}),(0,s.jsx)(n.td,{children:"Custom"}),(0,s.jsx)(n.td,{children:"Slower"}),(0,s.jsx)(n.td,{children:"Highest"}),(0,s.jsx)(n.td,{children:"Fine-tuned control, advanced parameters"})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"resolution-options-nano-banana-pro",children:"Resolution Options (Nano Banana Pro)"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"1K (1024px)"}),": Draft quality, fast generation, testing"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"2K (2048px)"}),": High-quality, good for web use"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"4K (4096px)"}),": Professional e-commerce quality (default, recommended)"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"environment-variables",children:"Environment Variables"}),"\n",(0,s.jsx)(n.p,{children:"Set the following environment variables for API keys:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# For LLM providers (choose one)\nexport OPENAI_API_KEY="your-openai-api-key"\n# OR\nexport ANTHROPIC_API_KEY="your-anthropic-api-key"\n# OR\nexport GOOGLE_API_KEY="your-google-api-key"\n\n# For model swapping APIs\nexport GEMINI_API_KEY="your-gemini-api-key"  # For Nano Banana models\nexport BFL_API_KEY="your-bfl-api-key"        # For FLUX 2 models\n'})}),"\n",(0,s.jsx)(n.h2,{id:"api-reference",children:"API Reference"}),"\n",(0,s.jsx)(n.h3,{id:"modelswapagent",children:"ModelSwapAgent"}),"\n",(0,s.jsx)(n.h4,{id:"__init__llm_provider-llm_modelnone-temperature00-api_keynone-modelnone-llm_kwargs",children:(0,s.jsx)(n.code,{children:"__init__(llm_provider, llm_model=None, temperature=0.0, api_key=None, model=None, **llm_kwargs)"})}),"\n",(0,s.jsx)(n.p,{children:"Initialize the Model Swap Agent."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"llm_provider"}),' (str): LLM provider to use. Options: "openai", "anthropic", "google"']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"llm_model"})," (str, optional): Specific model name. If None, uses default for provider"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"temperature"})," (float): Temperature for LLM (default: 0.0)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"api_key"})," (str, optional): API key for LLM provider"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"model"}),' (str, optional): Model to use for swapping. Options: "nano_banana", "nano_banana_pro", "flux2_pro", "flux2_flex". Default: "nano_banana_pro"']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"**llm_kwargs"}),": Additional keyword arguments for LLM initialization"]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"generateimage-prompt-resolutionnone-use_search_groundingfalse-verbosefalse-kwargs",children:(0,s.jsx)(n.code,{children:"generate(image, prompt, resolution=None, use_search_grounding=False, verbose=False, **kwargs)"})}),"\n",(0,s.jsx)(n.p,{children:"Generate model-swapped images using the agent."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"image"})," (str): Path or URL to the image of person wearing the outfit"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"prompt"})," (str): Natural language description of desired model/person"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"resolution"}),' (str, optional): Resolution for Nano Banana Pro. Options: "1K", "2K", "4K" (default: "4K")']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"use_search_grounding"})," (bool): Whether to use Google Search grounding for real-world references (Nano Banana Pro only)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"verbose"})," (bool): If True, print debug information about agent reasoning"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"**kwargs"}),": Additional parameters to pass to the agent"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Returns:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Dictionary containing:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"status"}),': "success" or "error"']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"provider"}),': Model provider used (e.g., "nano_banana_pro", "flux2_pro")']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"images"}),": List of generated images (PIL Images or base64 strings)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"model_description"}),": The detailed prompt used for generation"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"result"}),": Full agent response"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"error"}),': Error message (if status is "error")']}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"examples",children:"Examples"}),"\n",(0,s.jsx)(n.h3,{id:"example-1-basic-model-swap",children:"Example 1: Basic Model Swap"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from tryon.agents.model_swap import ModelSwapAgent\n\nagent = ModelSwapAgent(llm_provider="openai")\n\nresult = agent.generate(\n    image="model_wearing_outfit.jpg",\n    prompt="Replace with a professional Asian female model in her 30s, athletic build"\n)\n\nif result["status"] == "success":\n    for idx, image in enumerate(result[\'images\']):\n        image.save(f"swapped_model_{idx}.png")\n    print(f"Generated {len(result[\'images\'])} images")\n'})}),"\n",(0,s.jsx)(n.h3,{id:"example-2-high-quality-with-flux-2-pro",children:"Example 2: High-Quality with FLUX 2 Pro"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'agent = ModelSwapAgent(\n    llm_provider="openai",\n    model="flux2_pro"\n)\n\nresult = agent.generate(\n    image="model.jpg",\n    prompt="Professional male model in his 30s, athletic build, confident pose"\n)\n\nif result["status"] == "success":\n    result[\'images\'][0].save("high_quality_swap.png")\n'})}),"\n",(0,s.jsx)(n.h3,{id:"example-3-4k-professional-quality",children:"Example 3: 4K Professional Quality"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'agent = ModelSwapAgent(\n    llm_provider="openai",\n    model="nano_banana_pro"\n)\n\nresult = agent.generate(\n    image="outfit.jpg",\n    prompt=(\n        "Professional Asian female model in her early 30s, "\n        "athletic build, confident posture, sharp features, "\n        "editorial style photography"\n    ),\n    resolution="4K",\n    use_search_grounding=False,\n    verbose=True\n)\n\nif result["status"] == "success":\n    for idx, image in enumerate(result[\'images\']):\n        image.save(f"professional_4k_{idx}.png")\n    print(f"Model description: {result[\'model_description\']}")\n'})}),"\n",(0,s.jsx)(n.h3,{id:"example-4-advanced-control-with-flux-2-flex",children:"Example 4: Advanced Control with FLUX 2 Flex"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'agent = ModelSwapAgent(\n    llm_provider="anthropic",\n    model="flux2_flex"\n)\n\nresult = agent.generate(\n    image="model.jpg",\n    prompt="Plus-size woman, African American, 40s, friendly expression"\n)\n\nif result["status"] == "success":\n    result[\'images\'][0].save("flex_result.png")\n'})}),"\n",(0,s.jsx)(n.h2,{id:"how-it-works",children:"How It Works"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Prompt Analysis"}),": LLM agent extracts person attributes (gender, age, ethnicity, body type, pose, styling) from natural language prompts"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Prompt Construction"}),": Agent builds detailed, professional prompt emphasizing outfit preservation and maintaining original lighting, background, and composition"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Model Selection"}),": Uses the specified model (or default Nano Banana Pro) to generate images"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Image Generation"}),": Selected model generates up to 4K resolution images with perfect outfit preservation"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Be Specific"}),": Include age, gender, ethnicity, body type in prompts for better results"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Describe Pose"}),": Mention confident, casual, professional, etc. to guide the generation"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Mention Style"}),": Editorial, commercial, lifestyle photography helps set the tone"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Use 4K Resolution"}),": For professional e-commerce quality (Nano Banana Pro)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Trust the Agent"}),": Outfit preservation is automatic - focus on describing the desired model"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Choose the Right Model"}),":","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Use Nano Banana for quick iterations"}),"\n",(0,s.jsx)(n.li,{children:"Use Nano Banana Pro for professional 4K quality (default)"}),"\n",(0,s.jsx)(n.li,{children:"Use FLUX 2 Pro for custom dimensions"}),"\n",(0,s.jsx)(n.li,{children:"Use FLUX 2 Flex for advanced control"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"use-cases",children:"Use Cases"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"E-commerce Sellers"}),": Create professional product photos with diverse models"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Fashion Brands"}),": Showcase clothing on different body types and demographics"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Clothing Brands"}),": Generate consistent product imagery across model portfolios"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Product Photography"}),": Maintain styling and composition while varying models"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"limitations",children:"Limitations"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Resolution options (1K, 2K, 4K) are only available for Nano Banana Pro"}),"\n",(0,s.jsx)(n.li,{children:"Search grounding is only available for Nano Banana Pro"}),"\n",(0,s.jsx)(n.li,{children:"FLUX models don't support resolution presets (use custom width/height via API)"}),"\n",(0,s.jsx)(n.li,{children:"Agent output parsing may need refinement for complex scenarios"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"future-enhancements",children:"Future Enhancements"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Add support for more image generation models"}),"\n",(0,s.jsx)(n.li,{children:"Improve prompt understanding for better attribute extraction"}),"\n",(0,s.jsx)(n.li,{children:"Add support for batch processing"}),"\n",(0,s.jsx)(n.li,{children:"Implement result caching"}),"\n",(0,s.jsx)(n.li,{children:"Add support for video model swapping"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"related-documentation",children:"Related Documentation"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"/opentryon/agents/agent-ideas",children:"Agent Ideas"})," - Overview of Fashion AI Agents ecosystem"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"/opentryon/agents/vton-agent",children:"Virtual Try-On Agent"})," - Virtual try-on agent documentation"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"/opentryon/api-reference/nano-banana",children:"API Reference - Nano Banana"})," - Nano Banana adapter documentation"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"/opentryon/api-reference/flux2",children:"API Reference - FLUX 2"})," - FLUX 2 adapter documentation"]}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>o});var l=i(6540);const s={},a=l.createContext(s);function r(e){const n=l.useContext(a);return l.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),l.createElement(a.Provider,{value:n},e.children)}}}]);