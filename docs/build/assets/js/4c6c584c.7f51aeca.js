"use strict";(globalThis.webpackChunkopentryon_docs=globalThis.webpackChunkopentryon_docs||[]).push([[5381],{8453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>l});var o=i(6540);const r={},s=o.createContext(r);function t(e){const n=o.useContext(s);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),o.createElement(s.Provider,{value:n},e.children)}},9781:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>h,frontMatter:()=>t,metadata:()=>o,toc:()=>a});const o=JSON.parse('{"id":"api-reference/sora-video","title":"Sora (OpenAI Video Generation)","description":"Generate high-quality videos using OpenAI\'s Sora models (Sora 2 and Sora 2 Pro) with text-to-video and image-to-video capabilities.","source":"@site/docs/api-reference/sora-video.md","sourceDirName":"api-reference","slug":"/api-reference/sora-video","permalink":"/opentryon/api-reference/sora-video","draft":false,"unlisted":false,"editUrl":"https://github.com/tryonlabs/opentryon/tree/main/docs/docs/api-reference/sora-video.md","tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"sidebar_position":8,"title":"Sora (OpenAI Video Generation)","description":"Generate high-quality videos using OpenAI\'s Sora models (Sora 2 and Sora 2 Pro) with text-to-video and image-to-video capabilities.","keywords":["Sora 2","Sora 2 Pro","OpenAI video generation","video generation","text to video","image to video","video AI","fashion video"]},"sidebar":"tutorialSidebar","previous":{"title":"GPT-Image (OpenAI Image Generation)","permalink":"/opentryon/api-reference/gpt-image"},"next":{"title":"Utility Functions API Reference","permalink":"/opentryon/api-reference/utils"}}');var r=i(4848),s=i(8453);const t={sidebar_position:8,title:"Sora (OpenAI Video Generation)",description:"Generate high-quality videos using OpenAI's Sora models (Sora 2 and Sora 2 Pro) with text-to-video and image-to-video capabilities.",keywords:["Sora 2","Sora 2 Pro","OpenAI video generation","video generation","text to video","image to video","video AI","fashion video"]},l="Sora (OpenAI Video Generation)",d={},a=[{value:"Models Available",id:"models-available",level:2},{value:"<strong>Sora 2</strong> (Default)",id:"sora-2-default",level:3},{value:"<strong>Sora 2 Pro</strong>",id:"sora-2-pro",level:3},{value:"Features",id:"features",level:2},{value:"Installation",id:"installation",level:2},{value:"Configuration",id:"configuration",level:2},{value:"Basic Usage",id:"basic-usage",level:2},{value:"Text-to-Video Generation",id:"text-to-video-generation",level:3},{value:"Using Sora 2 Pro",id:"using-sora-2-pro",level:3},{value:"Image-to-Video Generation",id:"image-to-video-generation",level:3},{value:"Advanced Usage",id:"advanced-usage",level:2},{value:"Asynchronous Generation with Callbacks",id:"asynchronous-generation-with-callbacks",level:3},{value:"Manual Status Tracking",id:"manual-status-tracking",level:3},{value:"CLI Usage",id:"cli-usage",level:2},{value:"Basic Text-to-Video",id:"basic-text-to-video",level:3},{value:"High-Quality with Sora 2 Pro",id:"high-quality-with-sora-2-pro",level:3},{value:"Image-to-Video",id:"image-to-video",level:3},{value:"Asynchronous Mode",id:"asynchronous-mode",level:3},{value:"API Reference",id:"api-reference",level:2},{value:"SoraVideoAdapter",id:"soravideoadapter",level:3},{value:"Constructor",id:"constructor",level:4},{value:"generate_text_to_video()",id:"generate_text_to_video",level:4},{value:"generate_image_to_video()",id:"generate_image_to_video",level:4},{value:"generate_text_to_video_async()",id:"generate_text_to_video_async",level:4},{value:"generate_image_to_video_async()",id:"generate_image_to_video_async",level:4},{value:"get_video_status()",id:"get_video_status",level:4},{value:"download_video()",id:"download_video",level:4},{value:"Configuration Options",id:"configuration-options",level:2},{value:"Supported Resolutions",id:"supported-resolutions",level:3},{value:"Supported Durations",id:"supported-durations",level:3},{value:"Model Comparison",id:"model-comparison",level:2},{value:"Wait Mechanisms",id:"wait-mechanisms",level:2},{value:"1. Synchronous (Polling) - Default",id:"1-synchronous-polling---default",level:3},{value:"2. Asynchronous (Callbacks)",id:"2-asynchronous-callbacks",level:3},{value:"3. Manual Tracking",id:"3-manual-tracking",level:3},{value:"Common Use Cases",id:"common-use-cases",level:2},{value:"Fashion Runway Videos",id:"fashion-runway-videos",level:3},{value:"Product Animation",id:"product-animation",level:3},{value:"Fabric Visualization",id:"fabric-visualization",level:3},{value:"Model Portfolio Animation",id:"model-portfolio-animation",level:3},{value:"Error Handling",id:"error-handling",level:2},{value:"Performance Tips",id:"performance-tips",level:2},{value:"Limitations",id:"limitations",level:2},{value:"Related Documentation",id:"related-documentation",level:2},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"&quot;Video generation timeout&quot;",id:"video-generation-timeout",level:3},{value:"&quot;Invalid resolution&quot;",id:"invalid-resolution",level:3},{value:"&quot;API key not found&quot;",id:"api-key-not-found",level:3},{value:"Poor video quality",id:"poor-video-quality",level:3},{value:"Support",id:"support",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"sora-openai-video-generation",children:"Sora (OpenAI Video Generation)"})}),"\n",(0,r.jsxs)(n.p,{children:["Generate high-quality videos using OpenAI's ",(0,r.jsx)(n.strong,{children:"Sora 2"})," and ",(0,r.jsx)(n.strong,{children:"Sora 2 Pro"})," models. This adapter provides a unified interface for text-to-video and image-to-video generation with both synchronous (polling) and asynchronous (callback-based) wait mechanisms."]}),"\n",(0,r.jsx)(n.h2,{id:"models-available",children:"Models Available"}),"\n",(0,r.jsx)(n.p,{children:"OpenAI provides two Sora model variants:"}),"\n",(0,r.jsxs)(n.h3,{id:"sora-2-default",children:[(0,r.jsx)(n.strong,{children:"Sora 2"})," (Default)"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Model ID"}),": ",(0,r.jsx)(n.code,{children:"sora-2"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Best for"}),": Fast, high-quality video generation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Use cases"}),": Standard video generation, rapid prototyping, preview generation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Speed"}),": Faster generation times"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Quality"}),": High quality suitable for most applications"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"sora-2-pro",children:(0,r.jsx)(n.strong,{children:"Sora 2 Pro"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Model ID"}),": ",(0,r.jsx)(n.code,{children:"sora-2-pro"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Best for"}),": Premium quality with enhanced temporal consistency"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Use cases"}),": Professional video content, marketing materials, high-fidelity animations"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Speed"}),": Slower than Sora 2"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Quality"}),": Superior quality with better prompt understanding and frame consistency"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"features",children:"Features"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Text-to-Video"}),": Generate videos from text descriptions"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Image-to-Video"}),": Animate static images with text prompts"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Flexible Durations"}),": Support for 4, 8, and 12-second videos"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Multiple Resolutions"}),": From 720p to Full HD in various aspect ratios"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Two Wait Modes"}),": Synchronous (blocking) and asynchronous (callbacks)"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Progress Tracking"}),": Monitor video generation status"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Simple Python API"}),": Easy-to-use interface"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"CLI Support"}),": Command-line interface for quick generation"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"installation",children:"Installation"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"pip install openai\n"})}),"\n",(0,r.jsx)(n.h2,{id:"configuration",children:"Configuration"}),"\n",(0,r.jsx)(n.p,{children:"Set your OpenAI API key as an environment variable:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"export OPENAI_API_KEY='your-api-key-here'\n"})}),"\n",(0,r.jsx)(n.p,{children:"Or pass it directly when initializing the adapter."}),"\n",(0,r.jsx)(n.h2,{id:"basic-usage",children:"Basic Usage"}),"\n",(0,r.jsx)(n.h3,{id:"text-to-video-generation",children:"Text-to-Video Generation"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from tryon.api.openAI import SoraVideoAdapter\n\n# Initialize adapter (uses Sora 2 by default)\nadapter = SoraVideoAdapter()\n\n# Generate a video from text prompt (synchronous)\nvideo_bytes = adapter.generate_text_to_video(\n    prompt="A fashion model walking down a runway wearing an elegant evening gown",\n    duration=8,  # seconds\n    resolution="1920x1080"  # Full HD\n)\n\n# Save the video\nwith open("runway_walk.mp4", "wb") as f:\n    f.write(video_bytes)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"using-sora-2-pro",children:"Using Sora 2 Pro"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Initialize with Sora 2 Pro for higher quality\nadapter = SoraVideoAdapter(model_version="sora-2-pro")\n\nvideo_bytes = adapter.generate_text_to_video(\n    prompt="Cinematic slow-motion shot of fabric flowing in the wind",\n    duration=12,\n    resolution="1920x1080"\n)\n\nwith open("fabric_flow.mp4", "wb") as f:\n    f.write(video_bytes)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"image-to-video-generation",children:"Image-to-Video Generation"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Animate a static image\nadapter = SoraVideoAdapter()\n\nvideo_bytes = adapter.generate_image_to_video(\n    image="model_photo.jpg",\n    prompt="The model turns around and smiles at the camera",\n    duration=4,\n    resolution="1280x720"\n)\n\nwith open("animated_model.mp4", "wb") as f:\n    f.write(video_bytes)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"advanced-usage",children:"Advanced Usage"}),"\n",(0,r.jsx)(n.h3,{id:"asynchronous-generation-with-callbacks",children:"Asynchronous Generation with Callbacks"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'adapter = SoraVideoAdapter()\n\n# Define callback functions\ndef on_complete(video_bytes):\n    with open("output.mp4", "wb") as f:\n        f.write(video_bytes)\n    print("\u2705 Video generation complete!")\n\ndef on_error(error):\n    print(f"\u274c Error: {error}")\n\ndef on_progress(status):\n    print(f"Status: {status[\'status\']}, Progress: {status.get(\'progress\', \'N/A\')}")\n\n# Start async generation\nvideo_id = adapter.generate_text_to_video_async(\n    prompt="A person trying on different outfits in a fashion boutique",\n    duration=8,\n    resolution="1920x1080",\n    on_complete=on_complete,\n    on_error=on_error,\n    on_progress=on_progress\n)\n\nprint(f"Video generation started with ID: {video_id}")\n# Script continues immediately, callbacks will be invoked when ready\n'})}),"\n",(0,r.jsx)(n.h3,{id:"manual-status-tracking",children:"Manual Status Tracking"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Start generation without waiting\nvideo_id = adapter.generate_text_to_video(\n    prompt=\"Fashion runway show with multiple models\",\n    duration=12,\n    resolution=\"1920x1080\",\n    wait=False  # Return immediately\n)\n\n# Check status manually\nimport time\nwhile True:\n    status = adapter.get_video_status(video_id)\n    print(f\"Status: {status['status']}\")\n    \n    if status['status'] == 'completed':\n        video_bytes = adapter.download_video(video_id)\n        with open(\"runway_show.mp4\", \"wb\") as f:\n            f.write(video_bytes)\n        break\n    elif status['status'] == 'failed':\n        print(f\"Failed: {status.get('error')}\")\n        break\n    \n    time.sleep(5)\n"})}),"\n",(0,r.jsx)(n.h2,{id:"cli-usage",children:"CLI Usage"}),"\n",(0,r.jsx)(n.p,{children:"The package includes a command-line interface for easy video generation:"}),"\n",(0,r.jsx)(n.h3,{id:"basic-text-to-video",children:"Basic Text-to-Video"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'python sora_video.py --prompt "A fashion model walking in the rain" \\\n                     --output walk.mp4\n'})}),"\n",(0,r.jsx)(n.h3,{id:"high-quality-with-sora-2-pro",children:"High-Quality with Sora 2 Pro"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'python sora_video.py --prompt "Cinematic fashion runway show" \\\n                     --model sora-2-pro \\\n                     --duration 12 \\\n                     --resolution 1920x1080 \\\n                     --output runway.mp4\n'})}),"\n",(0,r.jsx)(n.h3,{id:"image-to-video",children:"Image-to-Video"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'python sora_video.py --image model_photo.jpg \\\n                     --prompt "The model waves and smiles" \\\n                     --duration 4 \\\n                     --output animated.mp4\n'})}),"\n",(0,r.jsx)(n.h3,{id:"asynchronous-mode",children:"Asynchronous Mode"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'python sora_video.py --prompt "Fabric flowing in slow motion" \\\n                     --duration 8 \\\n                     --async \\\n                     --output fabric.mp4\n'})}),"\n",(0,r.jsx)(n.h2,{id:"api-reference",children:"API Reference"}),"\n",(0,r.jsx)(n.h3,{id:"soravideoadapter",children:"SoraVideoAdapter"}),"\n",(0,r.jsx)(n.h4,{id:"constructor",children:"Constructor"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'SoraVideoAdapter(\n    api_key: Optional[str] = None,\n    model_version: str = "sora-2",\n    polling_interval: int = 5,\n    max_polling_time: int = 300\n)\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"api_key"})," (str, optional): OpenAI API key. Defaults to ",(0,r.jsx)(n.code,{children:"OPENAI_API_KEY"})," environment variable."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"model_version"})," (str, optional): Model to use. Options: ",(0,r.jsx)(n.code,{children:'"sora-2"'}),", ",(0,r.jsx)(n.code,{children:'"sora-2-pro"'}),". Default: ",(0,r.jsx)(n.code,{children:'"sora-2"'}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"polling_interval"})," (int, optional): Seconds between status checks. Default: 5."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"max_polling_time"})," (int, optional): Maximum wait time in seconds. Default: 300 (5 minutes)."]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"generate_text_to_video",children:"generate_text_to_video()"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'generate_text_to_video(\n    prompt: str,\n    duration: int = 4,\n    resolution: str = "1280x720",\n    wait: bool = True\n) -> Union[bytes, str]\n'})}),"\n",(0,r.jsx)(n.p,{children:"Generate a video from a text prompt."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"prompt"})," (str): Text description of the video content. ",(0,r.jsx)(n.strong,{children:"Required"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"duration"})," (int, optional): Video length in seconds. Options: ",(0,r.jsx)(n.code,{children:"4"}),", ",(0,r.jsx)(n.code,{children:"8"}),", ",(0,r.jsx)(n.code,{children:"12"}),". Default: ",(0,r.jsx)(n.code,{children:"4"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"resolution"})," (str, optional): Output resolution. See ",(0,r.jsx)(n.a,{href:"#supported-resolutions",children:"Supported Resolutions"}),". Default: ",(0,r.jsx)(n.code,{children:'"1280x720"'}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"wait"})," (bool, optional): If ",(0,r.jsx)(n.code,{children:"True"}),", waits for completion and returns video bytes. If ",(0,r.jsx)(n.code,{children:"False"}),", returns video ID immediately. Default: ",(0,r.jsx)(n.code,{children:"True"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Returns:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"bytes"}),": Video data (if ",(0,r.jsx)(n.code,{children:"wait=True"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"str"}),": Video generation ID (if ",(0,r.jsx)(n.code,{children:"wait=False"}),")"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Raises:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"ValueError"}),": If parameters are invalid"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"TimeoutError"}),": If generation exceeds ",(0,r.jsx)(n.code,{children:"max_polling_time"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"RuntimeError"}),": If generation fails"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"generate_image_to_video",children:"generate_image_to_video()"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'generate_image_to_video(\n    image: Union[str, io.BytesIO, Image.Image],\n    prompt: str,\n    duration: int = 4,\n    resolution: str = "1280x720",\n    wait: bool = True\n) -> Union[bytes, str]\n'})}),"\n",(0,r.jsx)(n.p,{children:"Generate a video from an image and text prompt."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"image"})," (Union[str, io.BytesIO, Image.Image]): Input image. Can be file path, BytesIO, or PIL Image. ",(0,r.jsx)(n.strong,{children:"Required"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"prompt"})," (str): Animation instructions. ",(0,r.jsx)(n.strong,{children:"Required"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"duration"})," (int, optional): Video length in seconds. Options: ",(0,r.jsx)(n.code,{children:"4"}),", ",(0,r.jsx)(n.code,{children:"8"}),", ",(0,r.jsx)(n.code,{children:"12"}),". Default: ",(0,r.jsx)(n.code,{children:"4"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"resolution"})," (str, optional): Output resolution. Default: ",(0,r.jsx)(n.code,{children:'"1280x720"'}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"wait"})," (bool, optional): Whether to wait for completion. Default: ",(0,r.jsx)(n.code,{children:"True"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Returns:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"bytes"}),": Video data (if ",(0,r.jsx)(n.code,{children:"wait=True"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"str"}),": Video generation ID (if ",(0,r.jsx)(n.code,{children:"wait=False"}),")"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"generate_text_to_video_async",children:"generate_text_to_video_async()"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'generate_text_to_video_async(\n    prompt: str,\n    duration: int = 4,\n    resolution: str = "1280x720",\n    on_complete: Optional[Callable[[bytes], None]] = None,\n    on_error: Optional[Callable[[str], None]] = None,\n    on_progress: Optional[Callable[[Dict[str, Any]], None]] = None\n) -> str\n'})}),"\n",(0,r.jsx)(n.p,{children:"Generate video asynchronously with callback functions."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"prompt"})," (str): Text description. ",(0,r.jsx)(n.strong,{children:"Required"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"duration"})," (int, optional): Video length in seconds. Default: ",(0,r.jsx)(n.code,{children:"4"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"resolution"})," (str, optional): Output resolution. Default: ",(0,r.jsx)(n.code,{children:'"1280x720"'}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"on_complete"})," (Callable, optional): Called with video bytes when complete."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"on_error"})," (Callable, optional): Called with error message if generation fails."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"on_progress"})," (Callable, optional): Called with status dict during generation."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Returns:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"str"}),": Video generation ID"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"generate_image_to_video_async",children:"generate_image_to_video_async()"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'generate_image_to_video_async(\n    image: Union[str, io.BytesIO, Image.Image],\n    prompt: str,\n    duration: int = 4,\n    resolution: str = "1280x720",\n    on_complete: Optional[Callable[[bytes], None]] = None,\n    on_error: Optional[Callable[[str], None]] = None,\n    on_progress: Optional[Callable[[Dict[str, Any]], None]] = None\n) -> str\n'})}),"\n",(0,r.jsx)(n.p,{children:"Generate video from image asynchronously with callbacks."}),"\n",(0,r.jsx)(n.h4,{id:"get_video_status",children:"get_video_status()"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"get_video_status(video_id: str) -> Dict[str, Any]\n"})}),"\n",(0,r.jsx)(n.p,{children:"Check the status of a video generation request."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Returns:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'{\n    "status": "queued" | "in_progress" | "completed" | "failed",\n    "id": "video_id",\n    "progress": 0-100,  # Optional\n    "url": "...",       # Only when completed\n    "file_id": "...",   # Only when completed\n    "error": "..."      # Only when failed\n}\n'})}),"\n",(0,r.jsx)(n.h4,{id:"download_video",children:"download_video()"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"download_video(video_id: str) -> bytes\n"})}),"\n",(0,r.jsx)(n.p,{children:"Download a completed video by its ID."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Raises:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"RuntimeError"}),": If video is not yet completed"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"configuration-options",children:"Configuration Options"}),"\n",(0,r.jsx)(n.h3,{id:"supported-resolutions",children:"Supported Resolutions"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Resolution"}),(0,r.jsx)(n.th,{children:"Aspect Ratio"}),(0,r.jsx)(n.th,{children:"Orientation"}),(0,r.jsx)(n.th,{children:"Use Case"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"720x1280"})}),(0,r.jsx)(n.td,{children:"9:16"}),(0,r.jsx)(n.td,{children:"Vertical"}),(0,r.jsx)(n.td,{children:"Mobile, Stories"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"1280x720"})}),(0,r.jsx)(n.td,{children:"16:9"}),(0,r.jsx)(n.td,{children:"Horizontal"}),(0,r.jsx)(n.td,{children:"Standard HD"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"1080x1920"})}),(0,r.jsx)(n.td,{children:"9:16"}),(0,r.jsx)(n.td,{children:"Vertical"}),(0,r.jsx)(n.td,{children:"Full HD Mobile"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"1920x1080"})}),(0,r.jsx)(n.td,{children:"16:9"}),(0,r.jsx)(n.td,{children:"Horizontal"}),(0,r.jsx)(n.td,{children:"Full HD Desktop"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"1024x1792"})}),(0,r.jsx)(n.td,{children:"~9:16"}),(0,r.jsx)(n.td,{children:"Tall Vertical"}),(0,r.jsx)(n.td,{children:"Special formats"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"1792x1024"})}),(0,r.jsx)(n.td,{children:"~16:9"}),(0,r.jsx)(n.td,{children:"Wide Horizontal"}),(0,r.jsx)(n.td,{children:"Cinematic"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"supported-durations",children:"Supported Durations"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"4 seconds"}),": Quick clips, previews, social media snippets"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"8 seconds"}),": Standard content, demonstrations, short narratives"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"12 seconds"}),": Extended content, detailed animations, storytelling"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"model-comparison",children:"Model Comparison"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Feature"}),(0,r.jsx)(n.th,{children:"Sora 2"}),(0,r.jsx)(n.th,{children:"Sora 2 Pro"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Speed"})}),(0,r.jsx)(n.td,{children:"Fast \u26a1"}),(0,r.jsx)(n.td,{children:"Slower \ud83d\udc22"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Quality"})}),(0,r.jsx)(n.td,{children:"High"}),(0,r.jsx)(n.td,{children:"Superior"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Temporal Consistency"})}),(0,r.jsx)(n.td,{children:"Good"}),(0,r.jsx)(n.td,{children:"Excellent"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Prompt Understanding"})}),(0,r.jsx)(n.td,{children:"Good"}),(0,r.jsx)(n.td,{children:"Superior"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Frame Coherence"})}),(0,r.jsx)(n.td,{children:"Good"}),(0,r.jsx)(n.td,{children:"Excellent"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Best For"})}),(0,r.jsx)(n.td,{children:"Rapid iteration, previews"}),(0,r.jsx)(n.td,{children:"Final production, marketing"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Cost"})}),(0,r.jsx)(n.td,{children:"Lower"}),(0,r.jsx)(n.td,{children:"Higher"})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"wait-mechanisms",children:"Wait Mechanisms"}),"\n",(0,r.jsx)(n.h3,{id:"1-synchronous-polling---default",children:"1. Synchronous (Polling) - Default"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"When to use:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Simple scripts"}),"\n",(0,r.jsx)(n.li,{children:"One-off generations"}),"\n",(0,r.jsx)(n.li,{children:"When you can block and wait"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"How it works:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'video_bytes = adapter.generate_text_to_video(\n    prompt="...",\n    wait=True  # Blocks until complete\n)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"2-asynchronous-callbacks",children:"2. Asynchronous (Callbacks)"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"When to use:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Multiple concurrent generations"}),"\n",(0,r.jsx)(n.li,{children:"Long-running applications"}),"\n",(0,r.jsx)(n.li,{children:"When you need progress updates"}),"\n",(0,r.jsx)(n.li,{children:"Non-blocking workflows"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"How it works:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'video_id = adapter.generate_text_to_video_async(\n    prompt="...",\n    on_complete=lambda bytes: save_video(bytes),\n    on_progress=lambda status: print(status)\n)\n# Continues immediately\n'})}),"\n",(0,r.jsx)(n.h3,{id:"3-manual-tracking",children:"3. Manual Tracking"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"When to use:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Custom control flow"}),"\n",(0,r.jsx)(n.li,{children:"Integration with existing systems"}),"\n",(0,r.jsx)(n.li,{children:"When you need fine-grained control"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"How it works:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Start without waiting\nvideo_id = adapter.generate_text_to_video(prompt=\"...\", wait=False)\n\n# Check status anytime\nstatus = adapter.get_video_status(video_id)\n\n# Download when ready\nif status['status'] == 'completed':\n    video_bytes = adapter.download_video(video_id)\n"})}),"\n",(0,r.jsx)(n.h2,{id:"common-use-cases",children:"Common Use Cases"}),"\n",(0,r.jsx)(n.h3,{id:"fashion-runway-videos",children:"Fashion Runway Videos"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'adapter = SoraVideoAdapter(model_version="sora-2-pro")\n\nvideo_bytes = adapter.generate_text_to_video(\n    prompt="Professional fashion runway show with model wearing elegant evening gown, "\n           "cinematic lighting, slow motion walk, professional photography",\n    duration=12,\n    resolution="1920x1080"\n)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"product-animation",children:"Product Animation"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'adapter = SoraVideoAdapter()\n\nvideo_bytes = adapter.generate_image_to_video(\n    image="product_photo.jpg",\n    prompt="360-degree rotation of the product, professional studio lighting",\n    duration=4,\n    resolution="1280x720"\n)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"fabric-visualization",children:"Fabric Visualization"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'video_bytes = adapter.generate_text_to_video(\n    prompt="Luxurious silk fabric flowing gracefully in slow motion, "\n           "golden hour lighting, close-up macro shot",\n    duration=8,\n    resolution="1920x1080"\n)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"model-portfolio-animation",children:"Model Portfolio Animation"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'adapter = SoraVideoAdapter()\n\nvideo_bytes = adapter.generate_image_to_video(\n    image="model_portrait.jpg",\n    prompt="Model turns head towards camera with confident expression, "\n           "professional studio lighting, fashion photography",\n    duration=4,\n    resolution="1080x1920"  # Vertical for mobile\n)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"error-handling",children:"Error Handling"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from tryon.api.openAI import SoraVideoAdapter\n\nadapter = SoraVideoAdapter()\n\ntry:\n    video_bytes = adapter.generate_text_to_video(\n        prompt="A fashion model walking",\n        duration=8,\n        resolution="1920x1080"\n    )\n    \n    with open("output.mp4", "wb") as f:\n        f.write(video_bytes)\n    \nexcept ValueError as e:\n    print(f"Invalid parameters: {e}")\nexcept TimeoutError as e:\n    print(f"Generation timeout: {e}")\nexcept RuntimeError as e:\n    print(f"Generation failed: {e}")\nexcept Exception as e:\n    print(f"Unexpected error: {e}")\n'})}),"\n",(0,r.jsx)(n.h2,{id:"performance-tips",children:"Performance Tips"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Use Sora 2 for iteration"}),": Start with Sora 2 for rapid prototyping, then switch to Sora 2 Pro for final output."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Optimize duration"}),": Longer videos take significantly more time. Use 4-second clips for testing."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Async for batch processing"}),": When generating multiple videos, use async mode to parallelize:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"for prompt in prompts:\n    adapter.generate_text_to_video_async(\n        prompt=prompt,\n        on_complete=lambda b: save_video(b)\n    )\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Monitor progress"}),": Use ",(0,r.jsx)(n.code,{children:"on_progress"})," callbacks to track generation status."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Handle timeouts gracefully"}),": Set appropriate ",(0,r.jsx)(n.code,{children:"max_polling_time"})," based on your duration and model."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"limitations",children:"Limitations"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Maximum video duration: 12 seconds"}),"\n",(0,r.jsx)(n.li,{children:"Generation time varies by duration and model (typically 1-5 minutes)"}),"\n",(0,r.jsx)(n.li,{children:"API rate limits apply (check OpenAI's documentation)"}),"\n",(0,r.jsx)(n.li,{children:"Video format: MP4 (H.264)"}),"\n",(0,r.jsx)(n.li,{children:"Frame rate: 24 FPS (default, may vary)"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"related-documentation",children:"Related Documentation"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://platform.openai.com/docs/guides/video-generation",children:"OpenAI Video Generation Guide"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"./gpt-image",children:"GPT-Image (OpenAI)"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"./flux2",children:"FLUX.2 Image Generation"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"./overview",children:"API Reference Overview"})}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,r.jsx)(n.h3,{id:"video-generation-timeout",children:'"Video generation timeout"'}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Increase ",(0,r.jsx)(n.code,{children:"max_polling_time"})," parameter"]}),"\n",(0,r.jsx)(n.li,{children:"Try a shorter duration (4s instead of 12s)"}),"\n",(0,r.jsx)(n.li,{children:"Check OpenAI API status"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"invalid-resolution",children:'"Invalid resolution"'}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Use one of the supported resolutions listed above"}),"\n",(0,r.jsxs)(n.li,{children:["Common safe choice: ",(0,r.jsx)(n.code,{children:'"1280x720"'})]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"api-key-not-found",children:'"API key not found"'}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Set ",(0,r.jsx)(n.code,{children:"OPENAI_API_KEY"})," environment variable"]}),"\n",(0,r.jsxs)(n.li,{children:["Or pass ",(0,r.jsx)(n.code,{children:"api_key"})," parameter explicitly"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"poor-video-quality",children:"Poor video quality"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Try using Sora 2 Pro instead of Sora 2"}),"\n",(0,r.jsx)(n.li,{children:"Refine your prompt with more details"}),"\n",(0,r.jsx)(n.li,{children:"Check resolution settings"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"support",children:"Support"}),"\n",(0,r.jsx)(n.p,{children:"For issues and questions:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["OpenAI API Support: ",(0,r.jsx)(n.a,{href:"https://help.openai.com/",children:"OpenAI Help Center"})]}),"\n",(0,r.jsxs)(n.li,{children:["OpenTryOn Issues: ",(0,r.jsx)(n.a,{href:"https://github.com/tryonlabs/opentryon/issues",children:"GitHub Issues"})]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}}}]);