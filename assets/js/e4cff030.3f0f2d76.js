"use strict";(globalThis.webpackChunkopentryon_docs=globalThis.webpackChunkopentryon_docs||[]).push([[6596],{4063:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>t,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"api-reference/ben2","title":"BEN2 - Background Erase Network","description":"BEN2 (Background Erase Network 2) is a state-of-the-art background removal model integrated into OpenTryOn. It provides high-quality background removal for fashion and product images, making it ideal for e-commerce, virtual try-on preprocessing, and product photography.","source":"@site/docs/api-reference/ben2.md","sourceDirName":"api-reference","slug":"/api-reference/ben2","permalink":"/opentryon/api-reference/ben2","draft":false,"unlisted":false,"editUrl":"https://github.com/tryonlabs/opentryon/tree/main/docs/docs/api-reference/ben2.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Sora (OpenAI Video Generation)","permalink":"/opentryon/api-reference/sora-video"},"next":{"title":"Utility Functions API Reference","permalink":"/opentryon/api-reference/utils"}}');var a=r(4848),s=r(8453);const o={},t="BEN2 - Background Erase Network",l={},d=[{value:"Overview",id:"overview",level:2},{value:"Key Features",id:"key-features",level:3},{value:"Requirements",id:"requirements",level:2},{value:"Installation",id:"installation",level:2},{value:"Quick Start",id:"quick-start",level:2},{value:"Single Image",id:"single-image",level:3},{value:"Batch Processing",id:"batch-processing",level:3},{value:"Command Line Usage",id:"command-line-usage",level:2},{value:"CLI Arguments",id:"cli-arguments",level:3},{value:"Python API",id:"python-api",level:2},{value:"<code>BEN2BackgroundRemoverAdapter</code>",id:"ben2backgroundremoveradapter",level:3},{value:"Constructor",id:"constructor",level:4},{value:"Methods",id:"methods",level:4},{value:"<code>remove_background</code>",id:"remove_background",level:5},{value:"<code>remove_background_batch</code>",id:"remove_background_batch",level:5},{value:"<code>load_image</code>",id:"load_image",level:5},{value:"Use Cases",id:"use-cases",level:2},{value:"Virtual Try-On Preprocessing",id:"virtual-try-on-preprocessing",level:3},{value:"E-Commerce Product Photos",id:"e-commerce-product-photos",level:3},{value:"Model Swap Preprocessing",id:"model-swap-preprocessing",level:3},{value:"Performance Tips",id:"performance-tips",level:2},{value:"GPU Acceleration",id:"gpu-acceleration",level:3},{value:"Batch Processing",id:"batch-processing-1",level:3},{value:"Refinement Trade-offs",id:"refinement-trade-offs",level:3},{value:"Model Architecture",id:"model-architecture",level:2},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Common Issues",id:"common-issues",level:3},{value:"CUDA Out of Memory",id:"cuda-out-of-memory",level:4},{value:"Weights Download Issues",id:"weights-download-issues",level:4},{value:"Image Format Issues",id:"image-format-issues",level:4},{value:"API Reference Summary",id:"api-reference-summary",level:2},{value:"Related Documentation",id:"related-documentation",level:2},{value:"References",id:"references",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",h5:"h5",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"ben2---background-erase-network",children:"BEN2 - Background Erase Network"})}),"\n",(0,a.jsx)(n.p,{children:"BEN2 (Background Erase Network 2) is a state-of-the-art background removal model integrated into OpenTryOn. It provides high-quality background removal for fashion and product images, making it ideal for e-commerce, virtual try-on preprocessing, and product photography."}),"\n",(0,a.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,a.jsx)(n.p,{children:"BEN2 uses a transformer-based architecture with window attention mechanisms for precise foreground-background separation. The model automatically downloads weights from Hugging Face on first use."}),"\n",(0,a.jsx)(n.h3,{id:"key-features",children:"Key Features"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"High Precision"}),": State-of-the-art accuracy for background removal"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Automatic Weight Download"}),": Weights automatically downloaded from ",(0,a.jsx)(n.a,{href:"https://huggingface.co/PramaLLC/BEN2",children:"Hugging Face"})]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Foreground Refinement"}),": Optional refinement for higher quality edges"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Batch Processing"}),": Process multiple images efficiently"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Flexible Input"}),": Accepts file paths, URLs, BytesIO, or PIL Images"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"GPU Acceleration"}),": CUDA support for faster processing"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"requirements",children:"Requirements"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"CUDA 11.8+"})," (recommended for GPU acceleration)"]}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.strong,{children:"PyTorch 2.1+"})}),"\n",(0,a.jsx)(n.li,{children:"Model weights are automatically cached after first download"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"installation",children:"Installation"}),"\n",(0,a.jsx)(n.p,{children:"BEN2 is included with OpenTryOn. The model weights are automatically downloaded on first use:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"pip install opentryon\n"})}),"\n",(0,a.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,a.jsx)(n.h3,{id:"single-image",children:"Single Image"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from tryon.api.ben2 import BEN2BackgroundRemoverAdapter\nfrom PIL import Image\n\n# Initialize adapter (weights download automatically on first use)\nadapter = BEN2BackgroundRemoverAdapter()\n\n# Remove background from a single image\nresult = adapter.remove_background("model.jpg")\n\n# Save the result (PNG with transparency)\nresult[0].save("model_no_bg.png")\n'})}),"\n",(0,a.jsx)(n.h3,{id:"batch-processing",children:"Batch Processing"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from tryon.api.ben2 import BEN2BackgroundRemoverAdapter\n\nadapter = BEN2BackgroundRemoverAdapter()\n\n# Process multiple images\nimages = ["model1.jpg", "model2.jpg", "model3.jpg"]\nresults = adapter.remove_background_batch(images)\n\n# Save all results\nfor i, img in enumerate(results):\n    img.save(f"output_{i+1}.png")\n'})}),"\n",(0,a.jsx)(n.h2,{id:"command-line-usage",children:"Command Line Usage"}),"\n",(0,a.jsx)(n.p,{children:"BEN2 can be used directly from the command line:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"# Single image background removal\npython bg_remove.py --mode single --image model.jpg --output_dir outputs\n\n# With foreground refinement for higher quality\npython bg_remove.py --mode single --image model.jpg --refine\n\n# Batch processing multiple images\npython bg_remove.py --mode batch --images model_1.jpg model_2.jpg model_3.jpg\n\n# Batch with refinement\npython bg_remove.py --mode batch --images *.jpg --refine --output_dir results\n"})}),"\n",(0,a.jsx)(n.h3,{id:"cli-arguments",children:"CLI Arguments"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Argument"}),(0,a.jsx)(n.th,{children:"Type"}),(0,a.jsx)(n.th,{children:"Default"}),(0,a.jsx)(n.th,{children:"Description"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"--mode"})}),(0,a.jsx)(n.td,{children:"string"}),(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"single"})}),(0,a.jsxs)(n.td,{children:["Processing mode: ",(0,a.jsx)(n.code,{children:"single"})," or ",(0,a.jsx)(n.code,{children:"batch"})]})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"--image"})}),(0,a.jsx)(n.td,{children:"string"}),(0,a.jsx)(n.td,{children:"-"}),(0,a.jsx)(n.td,{children:"Path/URL for single image mode"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"--images"})}),(0,a.jsx)(n.td,{children:"list"}),(0,a.jsx)(n.td,{children:"-"}),(0,a.jsx)(n.td,{children:"Multiple paths/URLs for batch mode"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"--output_dir"})}),(0,a.jsx)(n.td,{children:"string"}),(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"ben2_outputs"})}),(0,a.jsx)(n.td,{children:"Output directory for results"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"--refine"})}),(0,a.jsx)(n.td,{children:"flag"}),(0,a.jsx)(n.td,{children:"False"}),(0,a.jsx)(n.td,{children:"Enable foreground refinement"})]})]})]}),"\n",(0,a.jsx)(n.h2,{id:"python-api",children:"Python API"}),"\n",(0,a.jsx)(n.h3,{id:"ben2backgroundremoveradapter",children:(0,a.jsx)(n.code,{children:"BEN2BackgroundRemoverAdapter"})}),"\n",(0,a.jsx)(n.p,{children:"The main adapter class for background removal."}),"\n",(0,a.jsx)(n.h4,{id:"constructor",children:"Constructor"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'BEN2BackgroundRemoverAdapter(\n    weights_path: str = None,  # Custom weights path (optional)\n    device: str = None         # Device: "cuda" or "cpu" (auto-detected)\n)\n'})}),"\n",(0,a.jsx)(n.h4,{id:"methods",children:"Methods"}),"\n",(0,a.jsx)(n.h5,{id:"remove_background",children:(0,a.jsx)(n.code,{children:"remove_background"})}),"\n",(0,a.jsx)(n.p,{children:"Remove background from a single image."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"def remove_background(\n    self,\n    image: Union[str, io.BytesIO, Image.Image],\n    refine: bool = False\n) -> List[Image.Image]\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"image"}),": Input image (file path, URL, BytesIO, or PIL Image)"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"refine"}),": Enable foreground refinement for higher quality edges"]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Returns:"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"List containing a single PIL Image with transparent background"}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Example:"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'adapter = BEN2BackgroundRemoverAdapter()\n\n# From file path\nresult = adapter.remove_background("model.jpg")\n\n# From URL\nresult = adapter.remove_background("https://example.com/model.jpg")\n\n# From PIL Image\nfrom PIL import Image\nimg = Image.open("model.jpg")\nresult = adapter.remove_background(img)\n\n# With refinement\nresult = adapter.remove_background("model.jpg", refine=True)\n\n# Save result\nresult[0].save("output.png")\n'})}),"\n",(0,a.jsx)(n.h5,{id:"remove_background_batch",children:(0,a.jsx)(n.code,{children:"remove_background_batch"})}),"\n",(0,a.jsx)(n.p,{children:"Remove background from multiple images."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"def remove_background_batch(\n    self,\n    images: List[Union[str, io.BytesIO, Image.Image]],\n    refine: bool = False\n) -> List[Image.Image]\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"images"}),": List of input images (file paths, URLs, BytesIO, or PIL Images)"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"refine"}),": Enable foreground refinement for all images"]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Returns:"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"List of PIL Images with transparent backgrounds"}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Example:"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'adapter = BEN2BackgroundRemoverAdapter()\n\n# Process multiple images\nimages = [\n    "model1.jpg",\n    "model2.jpg",\n    "https://example.com/model3.jpg"\n]\n\nresults = adapter.remove_background_batch(images, refine=True)\n\n# Save all results\nfor i, img in enumerate(results):\n    img.save(f"output_{i+1}.png")\n\nprint(f"Processed {len(results)} images")\n'})}),"\n",(0,a.jsx)(n.h5,{id:"load_image",children:(0,a.jsx)(n.code,{children:"load_image"})}),"\n",(0,a.jsx)(n.p,{children:"Load and normalize image from various input formats."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"def load_image(\n    self,\n    input_data: Union[str, io.BytesIO, Image.Image]\n) -> Image.Image\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Supported Inputs:"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"File paths (local files)"}),"\n",(0,a.jsx)(n.li,{children:"URLs (http/https)"}),"\n",(0,a.jsx)(n.li,{children:"BytesIO / file-like objects"}),"\n",(0,a.jsx)(n.li,{children:"PIL Image objects"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"use-cases",children:"Use Cases"}),"\n",(0,a.jsx)(n.h3,{id:"virtual-try-on-preprocessing",children:"Virtual Try-On Preprocessing"}),"\n",(0,a.jsx)(n.p,{children:"Remove backgrounds from garment images before virtual try-on:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from tryon.api.ben2 import BEN2BackgroundRemoverAdapter\nfrom tryon.api import KlingAIVTONAdapter\n\n# Step 1: Remove garment background\nbg_adapter = BEN2BackgroundRemoverAdapter()\ngarment_clean = bg_adapter.remove_background("garment.jpg", refine=True)\ngarment_clean[0].save("garment_clean.png")\n\n# Step 2: Use cleaned garment for virtual try-on\nvton_adapter = KlingAIVTONAdapter()\nresult = vton_adapter.generate_and_decode(\n    source_image="model.jpg",\n    reference_image="garment_clean.png"\n)\n'})}),"\n",(0,a.jsx)(n.h3,{id:"e-commerce-product-photos",children:"E-Commerce Product Photos"}),"\n",(0,a.jsx)(n.p,{children:"Create professional product photos with transparent backgrounds:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from tryon.api.ben2 import BEN2BackgroundRemoverAdapter\nfrom pathlib import Path\n\nadapter = BEN2BackgroundRemoverAdapter()\n\n# Process all product images in a folder\ninput_dir = Path("raw_products")\noutput_dir = Path("processed_products")\noutput_dir.mkdir(exist_ok=True)\n\nimages = list(input_dir.glob("*.jpg"))\nresults = adapter.remove_background_batch([str(img) for img in images], refine=True)\n\nfor img_path, result in zip(images, results):\n    output_path = output_dir / f"{img_path.stem}.png"\n    result.save(output_path)\n    print(f"Processed: {output_path}")\n'})}),"\n",(0,a.jsx)(n.h3,{id:"model-swap-preprocessing",children:"Model Swap Preprocessing"}),"\n",(0,a.jsx)(n.p,{children:"Prepare images for model swapping:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from tryon.api.ben2 import BEN2BackgroundRemoverAdapter\n\nadapter = BEN2BackgroundRemoverAdapter()\n\n# Remove background for cleaner model swap\nperson_clean = adapter.remove_background("person.jpg", refine=True)\nperson_clean[0].save("person_clean.png")\n'})}),"\n",(0,a.jsx)(n.h2,{id:"performance-tips",children:"Performance Tips"}),"\n",(0,a.jsx)(n.h3,{id:"gpu-acceleration",children:"GPU Acceleration"}),"\n",(0,a.jsx)(n.p,{children:"BEN2 automatically uses CUDA if available:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import torch\n\n# Check if CUDA is available\nprint(f"CUDA available: {torch.cuda.is_available()}")\n\n# BEN2 will automatically use GPU if available\nadapter = BEN2BackgroundRemoverAdapter()  # Auto-detects device\n\n# Or explicitly set device\nadapter = BEN2BackgroundRemoverAdapter(device="cuda")  # Force GPU\nadapter = BEN2BackgroundRemoverAdapter(device="cpu")   # Force CPU\n'})}),"\n",(0,a.jsx)(n.h3,{id:"batch-processing-1",children:"Batch Processing"}),"\n",(0,a.jsx)(n.p,{children:"For multiple images, batch processing is more efficient:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"# Less efficient: processing one by one\nfor img in images:\n    result = adapter.remove_background(img)\n    # process result...\n\n# More efficient: batch processing\nresults = adapter.remove_background_batch(images)\nfor result in results:\n    # process results...\n"})}),"\n",(0,a.jsx)(n.h3,{id:"refinement-trade-offs",children:"Refinement Trade-offs"}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:"refine"})," parameter improves edge quality but increases processing time:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Fast processing (no refinement)\nresult = adapter.remove_background("image.jpg", refine=False)\n\n# Higher quality (with refinement) - takes longer\nresult = adapter.remove_background("image.jpg", refine=True)\n'})}),"\n",(0,a.jsx)(n.h2,{id:"model-architecture",children:"Model Architecture"}),"\n",(0,a.jsx)(n.p,{children:"BEN2 uses a Swin Transformer-based architecture with:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Window Attention"}),": Efficient self-attention in local windows"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Shifted Windows"}),": Cross-window connections for global context"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Multi-scale Processing"}),": Captures both fine details and global structure"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Foreground Refinement"}),": Optional post-processing for cleaner edges"]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["The model weights are downloaded from ",(0,a.jsx)(n.a,{href:"https://huggingface.co/PramaLLC/BEN2",children:"Hugging Face: PramaLLC/BEN2"}),"."]}),"\n",(0,a.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,a.jsx)(n.h3,{id:"common-issues",children:"Common Issues"}),"\n",(0,a.jsx)(n.h4,{id:"cuda-out-of-memory",children:"CUDA Out of Memory"}),"\n",(0,a.jsx)(n.p,{children:"For large images on limited GPU memory:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Use CPU instead\nadapter = BEN2BackgroundRemoverAdapter(device="cpu")\n\n# Or resize images before processing\nfrom PIL import Image\n\nimg = Image.open("large_image.jpg")\nimg.thumbnail((2048, 2048))  # Resize to max 2048px\nresult = adapter.remove_background(img)\n'})}),"\n",(0,a.jsx)(n.h4,{id:"weights-download-issues",children:"Weights Download Issues"}),"\n",(0,a.jsx)(n.p,{children:"If automatic download fails:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Manually download weights\nimport huggingface_hub\n\nhuggingface_hub.hf_hub_download(\n    repo_id="PramaLLC/BEN2",\n    filename="BEN2_Base.pth",\n    local_dir="tryon/api/ben2"\n)\n\n# Then use custom path\nadapter = BEN2BackgroundRemoverAdapter(\n    weights_path="tryon/api/ben2/BEN2_Base.pth"\n)\n'})}),"\n",(0,a.jsx)(n.h4,{id:"image-format-issues",children:"Image Format Issues"}),"\n",(0,a.jsx)(n.p,{children:"BEN2 automatically converts images to RGB:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# RGBA images are converted to RGB automatically\nresult = adapter.remove_background("image_with_alpha.png")\n\n# Grayscale images are also converted\nresult = adapter.remove_background("grayscale.jpg")\n'})}),"\n",(0,a.jsx)(n.h2,{id:"api-reference-summary",children:"API Reference Summary"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Method"}),(0,a.jsx)(n.th,{children:"Description"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"remove_background(image, refine=False)"})}),(0,a.jsx)(n.td,{children:"Remove background from single image"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"remove_background_batch(images, refine=False)"})}),(0,a.jsx)(n.td,{children:"Remove background from multiple images"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"load_image(input_data)"})}),(0,a.jsx)(n.td,{children:"Load image from path, URL, or BytesIO"})]})]})]}),"\n",(0,a.jsx)(n.h2,{id:"related-documentation",children:"Related Documentation"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"/preprocessing/overview",children:"Preprocessing Overview"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"/preprocessing/garment-segmentation",children:"Garment Segmentation"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"/api-reference/overview",children:"Virtual Try-On API"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"/api-reference/kling-ai",children:"Kling AI"})}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://huggingface.co/PramaLLC/BEN2",children:"BEN2 on Hugging Face"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://arxiv.org/abs/2103.14030",children:"Swin Transformer Paper"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>o,x:()=>t});var i=r(6540);const a={},s=i.createContext(a);function o(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);