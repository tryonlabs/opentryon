"use strict";(globalThis.webpackChunkopentryon_docs=globalThis.webpackChunkopentryon_docs||[]).push([[6007],{783:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>p,frontMatter:()=>s,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"agents/vton-agent","title":"Virtual Try-On Agent","description":"LangChain-based agent that intelligently selects and uses the appropriate virtual try-on adapter based on user prompts.","source":"@site/docs/agents/vton-agent.md","sourceDirName":"agents","slug":"/agents/vton-agent","permalink":"/opentryon/agents/vton-agent","draft":false,"unlisted":false,"editUrl":"https://github.com/tryonlabs/opentryon/tree/main/docs/docs/agents/vton-agent.md","tags":[],"version":"current","frontMatter":{"title":"Virtual Try-On Agent","description":"LangChain-based agent that intelligently selects and uses the appropriate virtual try-on adapter based on user prompts.","keywords":["virtual try-on agent","langchain agent","kling ai","nova canvas","segmind","AI agent","vton agent"]},"sidebar":"tutorialSidebar","previous":{"title":"Fashion AI Agents - Community Ideas","permalink":"/opentryon/agents/agent-ideas"},"next":{"title":"Model Swap Agent","permalink":"/opentryon/agents/model-swap-agent"}}');var i=r(4848),a=r(8453);const s={title:"Virtual Try-On Agent",description:"LangChain-based agent that intelligently selects and uses the appropriate virtual try-on adapter based on user prompts.",keywords:["virtual try-on agent","langchain agent","kling ai","nova canvas","segmind","AI agent","vton agent"]},l="Virtual Try-On Agent",o={},d=[{value:"Overview",id:"overview",level:2},{value:"Features",id:"features",level:2},{value:"Installation",id:"installation",level:2},{value:"Quick Start",id:"quick-start",level:2},{value:"Usage",id:"usage",level:2},{value:"Command Line Interface",id:"command-line-interface",level:3},{value:"CLI Arguments",id:"cli-arguments",level:4},{value:"Python API Usage",id:"python-api-usage",level:3},{value:"Basic Usage",id:"basic-usage",level:4},{value:"Provider Selection",id:"provider-selection",level:3},{value:"Using Different LLM Providers",id:"using-different-llm-providers",level:3},{value:"Environment Variables",id:"environment-variables",level:3},{value:"API Reference",id:"api-reference",level:2},{value:"VTOnAgent",id:"vtonagent",level:3},{value:"<code>__init__(llm_provider, llm_model=None, temperature=0.0, api_key=None, **llm_kwargs)</code>",id:"__init__llm_provider-llm_modelnone-temperature00-api_keynone-llm_kwargs",level:4},{value:"<code>generate(person_image, garment_image, prompt, **kwargs)</code>",id:"generateperson_image-garment_image-prompt-kwargs",level:4},{value:"Architecture",id:"architecture",level:2},{value:"Tool Structure",id:"tool-structure",level:3},{value:"Examples",id:"examples",level:2},{value:"Example 1: Basic Virtual Try-On",id:"example-1-basic-virtual-try-on",level:3},{value:"Example 2: Provider Selection",id:"example-2-provider-selection",level:3},{value:"Example 3: Custom Parameters",id:"example-3-custom-parameters",level:3},{value:"Limitations",id:"limitations",level:2},{value:"Future Enhancements",id:"future-enhancements",level:2},{value:"Related Documentation",id:"related-documentation",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"virtual-try-on-agent",children:"Virtual Try-On Agent"})}),"\n",(0,i.jsx)(n.p,{children:"A LangChain-based agent that intelligently selects and uses the appropriate virtual try-on adapter based on user prompts."}),"\n",(0,i.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"The Virtual Try-On Agent uses LangChain to analyze user requests and automatically select the best virtual try-on adapter. It supports multiple providers:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Kling AI"}),": High-quality virtual try-on with asynchronous processing"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Amazon Nova Canvas"}),": AWS Bedrock-based virtual try-on with automatic garment detection"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Segmind"}),": Fast and efficient virtual try-on generation"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"features",children:"Features"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Intelligent Provider Selection"}),": Automatically selects the adapter based on user prompts"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Natural Language Interface"}),": Accepts natural language prompts describing the desired operation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Multiple LLM Support"}),": Works with OpenAI, Anthropic Claude, and Google Gemini"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Flexible Input"}),": Supports file paths, URLs, and base64-encoded images"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Error Handling"}),": Comprehensive error handling and reporting"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"installation",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"pip install langchain langchain-openai langchain-anthropic langchain-google-genai\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Note"}),": This agent uses LangChain 1.x API (",(0,i.jsx)(n.code,{children:"create_agent"}),"). See ",(0,i.jsx)(n.a,{href:"https://docs.langchain.com/oss/python/langchain/agents",children:"LangChain 1.x documentation"})," for details."]}),"\n",(0,i.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from tryon.agents.vton import VTOnAgent\n\n# Initialize the agent\nagent = VTOnAgent(llm_provider="openai")\n\n# Generate virtual try-on\nresult = agent.generate(\n    person_image="person.jpg",\n    garment_image="shirt.jpg",\n    prompt="Use Kling AI to create a virtual try-on of this shirt"\n)\n\nprint(result)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"usage",children:"Usage"}),"\n",(0,i.jsx)(n.h3,{id:"command-line-interface",children:"Command Line Interface"}),"\n",(0,i.jsx)(n.p,{children:"The Virtual Try-On Agent includes a command-line interface for easy usage:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Basic usage with default OpenAI provider\npython vton_agent.py --person person.jpg --garment shirt.jpg --prompt "Create a virtual try-on using Kling AI"\n\n# Specify LLM provider\npython vton_agent.py --person person.jpg --garment shirt.jpg --prompt "Use Nova Canvas for virtual try-on" --llm-provider anthropic\n\n# Use Google Gemini as LLM\npython vton_agent.py --person person.jpg --garment shirt.jpg --prompt "Generate try-on with Segmind" --llm-provider google\n\n# Specify LLM model\npython vton_agent.py --person person.jpg --garment shirt.jpg --prompt "Use Kling AI" --llm-model gpt-4-turbo-preview\n\n# Save output to specific directory\npython vton_agent.py --person person.jpg --garment shirt.jpg --prompt "Create virtual try-on" --output-dir results/\n\n# Use URLs instead of file paths\npython vton_agent.py --person https://example.com/person.jpg --garment https://example.com/shirt.jpg --prompt "Use Kling AI"\n\n# Verbose output to see agent reasoning\npython vton_agent.py --person person.jpg --garment shirt.jpg --prompt "Use Kling AI" --verbose\n'})}),"\n",(0,i.jsx)(n.h4,{id:"cli-arguments",children:"CLI Arguments"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"--person"}),", ",(0,i.jsx)(n.code,{children:"-p"}),": Path or URL to person/model image (required)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"--garment"}),", ",(0,i.jsx)(n.code,{children:"-g"}),": Path or URL to garment/cloth image (required)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"--prompt"}),": Natural language prompt describing the virtual try-on request (required)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"--llm-provider"}),": LLM provider to use (default: ",(0,i.jsx)(n.code,{children:"openai"}),", options: ",(0,i.jsx)(n.code,{children:"openai"}),", ",(0,i.jsx)(n.code,{children:"anthropic"}),", ",(0,i.jsx)(n.code,{children:"google"}),")"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"--llm-model"}),": Specific LLM model name (optional, uses default for provider)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"--llm-temperature"}),": Temperature for LLM (default: ",(0,i.jsx)(n.code,{children:"0.0"}),")"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"--llm-api-key"}),": API key for LLM provider (optional, can use environment variables)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"--output-dir"}),", ",(0,i.jsx)(n.code,{children:"-o"}),": Directory to save generated images (default: ",(0,i.jsx)(n.code,{children:"outputs/"}),")"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"--save-base64"}),": Also save Base64 encoded strings to .txt files"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"--verbose"}),": Print verbose output including agent reasoning steps"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"python-api-usage",children:"Python API Usage"}),"\n",(0,i.jsx)(n.h4,{id:"basic-usage",children:"Basic Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from tryon.agents.vton import VTOnAgent\n\nagent = VTOnAgent(llm_provider="openai")\n\nresult = agent.generate(\n    person_image="path/to/person.jpg",\n    garment_image="path/to/garment.jpg",\n    prompt="Generate a virtual try-on using Nova Canvas"\n)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"provider-selection",children:"Provider Selection"}),"\n",(0,i.jsx)(n.p,{children:"The agent automatically selects the provider based on keywords in your prompt:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Kling AI"}),': "kling ai", "kling", "kolors"']}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Nova Canvas"}),': "nova canvas", "amazon nova", "aws", "bedrock"']}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Segmind"}),': "segmind"']}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Examples:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Uses Kling AI\nresult = agent.generate(\n    person_image="person.jpg",\n    garment_image="shirt.jpg",\n    prompt="Use Kling AI to generate the try-on"\n)\n\n# Uses Nova Canvas\nresult = agent.generate(\n    person_image="person.jpg",\n    garment_image="shirt.jpg",\n    prompt="Generate with Amazon Nova Canvas"\n)\n\n# Uses Segmind\nresult = agent.generate(\n    person_image="person.jpg",\n    garment_image="shirt.jpg",\n    prompt="Try Segmind for this virtual try-on"\n)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"using-different-llm-providers",children:"Using Different LLM Providers"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# OpenAI\nagent = VTOnAgent(llm_provider="openai", llm_model="gpt-4-turbo-preview")\n\n# Anthropic Claude\nagent = VTOnAgent(llm_provider="anthropic", llm_model="claude-3-opus-20240229")\n\n# Google Gemini\nagent = VTOnAgent(llm_provider="google", llm_model="gemini-pro")\n'})}),"\n",(0,i.jsx)(n.h3,{id:"environment-variables",children:"Environment Variables"}),"\n",(0,i.jsx)(n.p,{children:"Set the following environment variables for API keys:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# For OpenAI\nexport OPENAI_API_KEY="your-openai-api-key"\n\n# For Anthropic\nexport ANTHROPIC_API_KEY="your-anthropic-api-key"\n\n# For Google\nexport GOOGLE_API_KEY="your-google-api-key"\n\n# For Virtual Try-On APIs\nexport KLING_AI_API_KEY="your-kling-api-key"\nexport KLING_AI_SECRET_KEY="your-kling-secret-key"\nexport SEGMIND_API_KEY="your-segmind-api-key"\nexport AMAZON_NOVA_REGION="us-east-1"  # For Nova Canvas\n'})}),"\n",(0,i.jsx)(n.h2,{id:"api-reference",children:"API Reference"}),"\n",(0,i.jsx)(n.h3,{id:"vtonagent",children:"VTOnAgent"}),"\n",(0,i.jsx)(n.h4,{id:"__init__llm_provider-llm_modelnone-temperature00-api_keynone-llm_kwargs",children:(0,i.jsx)(n.code,{children:"__init__(llm_provider, llm_model=None, temperature=0.0, api_key=None, **llm_kwargs)"})}),"\n",(0,i.jsx)(n.p,{children:"Initialize the Virtual Try-On Agent."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"llm_provider"}),' (str): LLM provider to use. Options: "openai", "anthropic", "google"']}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"llm_model"})," (str, optional): Specific model name. If None, uses default for provider"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"temperature"})," (float): Temperature for LLM (default: 0.0)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"api_key"})," (str, optional): API key for LLM provider"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"**llm_kwargs"}),": Additional keyword arguments for LLM initialization"]}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"generateperson_image-garment_image-prompt-kwargs",children:(0,i.jsx)(n.code,{children:"generate(person_image, garment_image, prompt, **kwargs)"})}),"\n",(0,i.jsx)(n.p,{children:"Generate virtual try-on images using the agent."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"person_image"})," (str): Path or URL to the person/model image"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"garment_image"})," (str): Path or URL to the garment/cloth image"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"prompt"})," (str): Natural language prompt describing the request"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"**kwargs"}),": Additional parameters to pass to the agent"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Returns:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Dictionary containing:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"status"}),': "success" or "error"']}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"provider"}),": Name of the provider used"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"images"}),": List of generated images (URLs or base64 strings)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"result"}),": Full agent response"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"error"}),': Error message (if status is "error")']}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"architecture",children:"Architecture"}),"\n",(0,i.jsx)(n.p,{children:"The agent uses LangChain's ReAct agent framework:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Tools"}),": Each virtual try-on adapter is wrapped as a LangChain tool"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Agent"}),": A ReAct agent that selects and uses tools based on user prompts"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"LLM"}),": Language model (OpenAI, Anthropic, or Google) that powers the agent"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"tool-structure",children:"Tool Structure"}),"\n",(0,i.jsx)(n.p,{children:"Each tool follows this pattern:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'@tool("provider_name_virtual_tryon", args_schema=InputSchema)\ndef provider_virtual_tryon(person_image, garment_image, **kwargs):\n    """Tool description"""\n    adapter = ProviderAdapter()\n    result = adapter.generate(...)\n    return result\n'})}),"\n",(0,i.jsx)(n.h2,{id:"examples",children:"Examples"}),"\n",(0,i.jsx)(n.h3,{id:"example-1-basic-virtual-try-on",children:"Example 1: Basic Virtual Try-On"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from tryon.agents.vton import VTOnAgent\n\nagent = VTOnAgent(llm_provider="openai")\n\nresult = agent.generate(\n    person_image="https://example.com/person.jpg",\n    garment_image="https://example.com/shirt.jpg",\n    prompt="Create a virtual try-on using Kling AI"\n)\n\nif result["status"] == "success":\n    print(f"Generated {len(result[\'images\'])} images using {result[\'provider\']}")\nelse:\n    print(f"Error: {result.get(\'error\')}")\n'})}),"\n",(0,i.jsx)(n.h3,{id:"example-2-provider-selection",children:"Example 2: Provider Selection"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'agent = VTOnAgent(llm_provider="anthropic")\n\n# The agent will select Kling AI based on the prompt\nresult = agent.generate(\n    person_image="person.jpg",\n    garment_image="dress.jpg",\n    prompt="I want to see how this dress looks. Use Kling AI for best quality."\n)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"example-3-custom-parameters",children:"Example 3: Custom Parameters"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'agent = VTOnAgent(llm_provider="google")\n\n# The agent can extract parameters from the prompt\nresult = agent.generate(\n    person_image="person.jpg",\n    garment_image="pants.jpg",\n    prompt="Generate virtual try-on with Nova Canvas for lower body garment"\n)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"limitations",children:"Limitations"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Currently supports only dedicated virtual try-on APIs (Kling AI, Nova Canvas, Segmind)"}),"\n",(0,i.jsx)(n.li,{children:"Image generation APIs (Nano Banana Pro, FLUX 2 Pro, FLUX 2 Flex) are not yet integrated"}),"\n",(0,i.jsx)(n.li,{children:"No vector store support (as requested)"}),"\n",(0,i.jsx)(n.li,{children:"Agent output parsing may need refinement for complex scenarios"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"future-enhancements",children:"Future Enhancements"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Add support for image generation APIs (Nano Banana Pro, FLUX 2 Pro, FLUX 2 Flex)"}),"\n",(0,i.jsx)(n.li,{children:"Improve prompt understanding for better parameter extraction"}),"\n",(0,i.jsx)(n.li,{children:"Add support for batch processing"}),"\n",(0,i.jsx)(n.li,{children:"Implement image decoding utilities"}),"\n",(0,i.jsx)(n.li,{children:"Add result caching"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"related-documentation",children:"Related Documentation"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"/opentryon/agents/agent-ideas",children:"Agent Ideas"})," - Overview of Fashion AI Agents ecosystem"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"/opentryon/api-reference/kling-ai",children:"API Reference - Kling AI"})," - Kling AI adapter documentation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"/opentryon/api-reference/nova-canvas",children:"API Reference - Nova Canvas"})," - Nova Canvas adapter documentation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"/opentryon/api-reference/segmind",children:"API Reference - Segmind"})," - Segmind adapter documentation"]}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>s,x:()=>l});var t=r(6540);const i={},a=t.createContext(i);function s(e){const n=t.useContext(a);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);